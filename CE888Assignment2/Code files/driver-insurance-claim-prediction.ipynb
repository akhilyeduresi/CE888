{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Loading required libraries\n",
    "import os\n",
    "import gc\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model, Sequential \n",
    "from keras.optimizers import Adam\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from pylab import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading train data\n",
    "train=pd.read_csv(\"../input/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <th>ps_ind_14</th>\n",
       "      <th>ps_ind_15</th>\n",
       "      <th>ps_ind_16_bin</th>\n",
       "      <th>ps_ind_17_bin</th>\n",
       "      <th>ps_ind_18_bin</th>\n",
       "      <th>ps_reg_01</th>\n",
       "      <th>ps_reg_02</th>\n",
       "      <th>ps_reg_03</th>\n",
       "      <th>ps_car_01_cat</th>\n",
       "      <th>ps_car_02_cat</th>\n",
       "      <th>ps_car_03_cat</th>\n",
       "      <th>ps_car_04_cat</th>\n",
       "      <th>ps_car_05_cat</th>\n",
       "      <th>ps_car_06_cat</th>\n",
       "      <th>ps_car_07_cat</th>\n",
       "      <th>ps_car_08_cat</th>\n",
       "      <th>ps_car_09_cat</th>\n",
       "      <th>ps_car_10_cat</th>\n",
       "      <th>ps_car_11_cat</th>\n",
       "      <th>ps_car_11</th>\n",
       "      <th>ps_car_12</th>\n",
       "      <th>ps_car_13</th>\n",
       "      <th>ps_car_14</th>\n",
       "      <th>ps_car_15</th>\n",
       "      <th>ps_calc_01</th>\n",
       "      <th>ps_calc_02</th>\n",
       "      <th>ps_calc_03</th>\n",
       "      <th>ps_calc_04</th>\n",
       "      <th>ps_calc_05</th>\n",
       "      <th>ps_calc_06</th>\n",
       "      <th>ps_calc_07</th>\n",
       "      <th>ps_calc_08</th>\n",
       "      <th>ps_calc_09</th>\n",
       "      <th>ps_calc_10</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.718070</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.883679</td>\n",
       "      <td>0.370810</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.766078</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.618817</td>\n",
       "      <td>0.388716</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.641586</td>\n",
       "      <td>0.347275</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.580948</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>0.374166</td>\n",
       "      <td>0.542949</td>\n",
       "      <td>0.294958</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.840759</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>0.316070</td>\n",
       "      <td>0.565832</td>\n",
       "      <td>0.365103</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target       ...        ps_calc_19_bin  ps_calc_20_bin\n",
       "0   7       0       ...                     0               1\n",
       "1   9       0       ...                     1               0\n",
       "2  13       0       ...                     1               0\n",
       "3  16       0       ...                     0               0\n",
       "4  17       0       ...                     1               0\n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "66a23fb00fbb13e03be02a99b45150868d49e4ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 59)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of data\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data subset\n",
    "train , _ = train_test_split(train, train_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59521, 59)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of data\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploring missing values\n",
    "train.isnull().sum()[train.isnull().sum() !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replaceming missing values witn Nan\n",
    "train = train.replace(-1, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ps_ind_02_cat       17\n",
       "ps_ind_04_cat        5\n",
       "ps_ind_05_cat      600\n",
       "ps_reg_03        10882\n",
       "ps_car_01_cat        7\n",
       "ps_car_03_cat    40944\n",
       "ps_car_05_cat    26467\n",
       "ps_car_07_cat     1127\n",
       "ps_car_09_cat       46\n",
       "ps_car_11            1\n",
       "ps_car_14         4268\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Again missing values check\n",
    "train.isnull().sum()[train.isnull().sum() !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_count_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ps_ind_02_cat</td>\n",
       "      <td>17</td>\n",
       "      <td>0.002856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ps_ind_04_cat</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ps_ind_05_cat</td>\n",
       "      <td>600</td>\n",
       "      <td>0.100804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ps_reg_03</td>\n",
       "      <td>10882</td>\n",
       "      <td>1.828256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ps_car_01_cat</td>\n",
       "      <td>7</td>\n",
       "      <td>0.001176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ps_car_03_cat</td>\n",
       "      <td>40944</td>\n",
       "      <td>6.878894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ps_car_05_cat</td>\n",
       "      <td>26467</td>\n",
       "      <td>4.446651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ps_car_07_cat</td>\n",
       "      <td>1127</td>\n",
       "      <td>0.189344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ps_car_09_cat</td>\n",
       "      <td>46</td>\n",
       "      <td>0.007728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ps_car_11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ps_car_14</td>\n",
       "      <td>4268</td>\n",
       "      <td>0.717055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         features            ...             missing_count_percentage\n",
       "0   ps_ind_02_cat            ...                             0.002856\n",
       "1   ps_ind_04_cat            ...                             0.000840\n",
       "2   ps_ind_05_cat            ...                             0.100804\n",
       "3       ps_reg_03            ...                             1.828256\n",
       "4   ps_car_01_cat            ...                             0.001176\n",
       "5   ps_car_03_cat            ...                             6.878894\n",
       "6   ps_car_05_cat            ...                             4.446651\n",
       "7   ps_car_07_cat            ...                             0.189344\n",
       "8   ps_car_09_cat            ...                             0.007728\n",
       "9       ps_car_11            ...                             0.000168\n",
       "10      ps_car_14            ...                             0.717055\n",
       "\n",
       "[11 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Missing values in percentage\n",
    "train_missing= train.isnull().sum()[train.isnull().sum() !=0]\n",
    "train_missing=pd.DataFrame(train_missing.reset_index())\n",
    "train_missing.rename(columns={'index':'features',0:'missing_count'},inplace=True)\n",
    "train_missing['missing_count_percentage']=((train_missing['missing_count'])/595212)*100\n",
    "plt.figure(figsize=(20,8))\n",
    "sns.barplot(y=train_missing['features'],x=train_missing['missing_count_percentage'])\n",
    "train_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <th>ps_ind_14</th>\n",
       "      <th>ps_ind_15</th>\n",
       "      <th>ps_ind_16_bin</th>\n",
       "      <th>ps_ind_17_bin</th>\n",
       "      <th>ps_ind_18_bin</th>\n",
       "      <th>ps_reg_01</th>\n",
       "      <th>ps_reg_02</th>\n",
       "      <th>ps_reg_03</th>\n",
       "      <th>ps_car_01_cat</th>\n",
       "      <th>ps_car_02_cat</th>\n",
       "      <th>ps_car_03_cat</th>\n",
       "      <th>ps_car_04_cat</th>\n",
       "      <th>ps_car_05_cat</th>\n",
       "      <th>ps_car_06_cat</th>\n",
       "      <th>ps_car_07_cat</th>\n",
       "      <th>ps_car_08_cat</th>\n",
       "      <th>ps_car_09_cat</th>\n",
       "      <th>ps_car_10_cat</th>\n",
       "      <th>ps_car_11_cat</th>\n",
       "      <th>ps_car_11</th>\n",
       "      <th>ps_car_12</th>\n",
       "      <th>ps_car_13</th>\n",
       "      <th>ps_car_14</th>\n",
       "      <th>ps_car_15</th>\n",
       "      <th>ps_calc_01</th>\n",
       "      <th>ps_calc_02</th>\n",
       "      <th>ps_calc_03</th>\n",
       "      <th>ps_calc_04</th>\n",
       "      <th>ps_calc_05</th>\n",
       "      <th>ps_calc_06</th>\n",
       "      <th>ps_calc_07</th>\n",
       "      <th>ps_calc_08</th>\n",
       "      <th>ps_calc_09</th>\n",
       "      <th>ps_calc_10</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.952100e+04</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59504.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59516.000000</td>\n",
       "      <td>58921.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>48639.000000</td>\n",
       "      <td>59514.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>18577.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>33054.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>58394.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59475.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59520.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>55253.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "      <td>59521.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.454628e+05</td>\n",
       "      <td>0.036239</td>\n",
       "      <td>1.905227</td>\n",
       "      <td>1.364312</td>\n",
       "      <td>4.428000</td>\n",
       "      <td>0.415670</td>\n",
       "      <td>0.426995</td>\n",
       "      <td>0.392467</td>\n",
       "      <td>0.254414</td>\n",
       "      <td>0.165202</td>\n",
       "      <td>0.187917</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.009560</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>7.306917</td>\n",
       "      <td>0.662707</td>\n",
       "      <td>0.122663</td>\n",
       "      <td>0.150922</td>\n",
       "      <td>0.610418</td>\n",
       "      <td>0.439976</td>\n",
       "      <td>0.894180</td>\n",
       "      <td>8.299257</td>\n",
       "      <td>0.833269</td>\n",
       "      <td>0.606449</td>\n",
       "      <td>0.727794</td>\n",
       "      <td>0.526563</td>\n",
       "      <td>6.505418</td>\n",
       "      <td>0.948145</td>\n",
       "      <td>0.830295</td>\n",
       "      <td>1.329063</td>\n",
       "      <td>0.992389</td>\n",
       "      <td>62.049193</td>\n",
       "      <td>2.344607</td>\n",
       "      <td>0.380047</td>\n",
       "      <td>0.812703</td>\n",
       "      <td>0.374572</td>\n",
       "      <td>3.067908</td>\n",
       "      <td>0.448378</td>\n",
       "      <td>0.451792</td>\n",
       "      <td>0.450083</td>\n",
       "      <td>2.372306</td>\n",
       "      <td>1.894323</td>\n",
       "      <td>7.689521</td>\n",
       "      <td>3.005662</td>\n",
       "      <td>9.225853</td>\n",
       "      <td>2.335361</td>\n",
       "      <td>8.411905</td>\n",
       "      <td>5.440786</td>\n",
       "      <td>1.447960</td>\n",
       "      <td>2.877808</td>\n",
       "      <td>7.544329</td>\n",
       "      <td>0.121974</td>\n",
       "      <td>0.628064</td>\n",
       "      <td>0.553788</td>\n",
       "      <td>0.289847</td>\n",
       "      <td>0.352665</td>\n",
       "      <td>0.155777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.293460e+05</td>\n",
       "      <td>0.186887</td>\n",
       "      <td>1.988299</td>\n",
       "      <td>0.667129</td>\n",
       "      <td>2.697662</td>\n",
       "      <td>0.492841</td>\n",
       "      <td>1.361146</td>\n",
       "      <td>0.488304</td>\n",
       "      <td>0.435535</td>\n",
       "      <td>0.371366</td>\n",
       "      <td>0.390649</td>\n",
       "      <td>0.019222</td>\n",
       "      <td>0.040337</td>\n",
       "      <td>0.097306</td>\n",
       "      <td>0.030384</td>\n",
       "      <td>0.126717</td>\n",
       "      <td>3.540153</td>\n",
       "      <td>0.472790</td>\n",
       "      <td>0.328052</td>\n",
       "      <td>0.357975</td>\n",
       "      <td>0.287668</td>\n",
       "      <td>0.405155</td>\n",
       "      <td>0.345260</td>\n",
       "      <td>2.500181</td>\n",
       "      <td>0.372739</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>2.152080</td>\n",
       "      <td>0.499301</td>\n",
       "      <td>5.495829</td>\n",
       "      <td>0.221735</td>\n",
       "      <td>0.375376</td>\n",
       "      <td>0.974150</td>\n",
       "      <td>0.091062</td>\n",
       "      <td>33.094695</td>\n",
       "      <td>0.837277</td>\n",
       "      <td>0.057951</td>\n",
       "      <td>0.222342</td>\n",
       "      <td>0.045766</td>\n",
       "      <td>0.729719</td>\n",
       "      <td>0.288438</td>\n",
       "      <td>0.287425</td>\n",
       "      <td>0.287368</td>\n",
       "      <td>1.118197</td>\n",
       "      <td>1.138533</td>\n",
       "      <td>1.333315</td>\n",
       "      <td>1.417590</td>\n",
       "      <td>1.453542</td>\n",
       "      <td>1.246816</td>\n",
       "      <td>2.881609</td>\n",
       "      <td>2.320967</td>\n",
       "      <td>1.210665</td>\n",
       "      <td>1.699938</td>\n",
       "      <td>2.739316</td>\n",
       "      <td>0.327258</td>\n",
       "      <td>0.483325</td>\n",
       "      <td>0.497103</td>\n",
       "      <td>0.453695</td>\n",
       "      <td>0.477804</td>\n",
       "      <td>0.362647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.291193</td>\n",
       "      <td>0.118322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.716530e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.633936</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.671498</td>\n",
       "      <td>0.349857</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.492730e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.801171</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.374166</td>\n",
       "      <td>0.766256</td>\n",
       "      <td>0.373497</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.115840e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.086566</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.905639</td>\n",
       "      <td>0.398497</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.487992e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>3.490791</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.264911</td>\n",
       "      <td>3.442563</td>\n",
       "      <td>0.631664</td>\n",
       "      <td>3.741657</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       ...        ps_calc_20_bin\n",
       "count  5.952100e+04       ...          59521.000000\n",
       "mean   7.454628e+05       ...              0.155777\n",
       "std    4.293460e+05       ...              0.362647\n",
       "min    1.600000e+01       ...              0.000000\n",
       "25%    3.716530e+05       ...              0.000000\n",
       "50%    7.492730e+05       ...              0.000000\n",
       "75%    1.115840e+06       ...              0.000000\n",
       "max    1.487992e+06       ...              1.000000\n",
       "\n",
       "[8 rows x 59 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Outlier detection\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Missing value Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mode imputation for Categoricval variables\n",
    "Categorical  = ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', \n",
    "                   'ps_car_03_cat', 'ps_car_05_cat', 'ps_car_07_cat', 'ps_car_09_cat', 'ps_car_11']\n",
    "\n",
    "train[Categorical] = train[Categorical].apply(lambda x:x.fillna(x.value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_count_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ps_reg_03</td>\n",
       "      <td>10882</td>\n",
       "      <td>18.325727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ps_car_14</td>\n",
       "      <td>4268</td>\n",
       "      <td>7.187484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    features  missing_count  missing_count_percentage\n",
       "0  ps_reg_03          10882                 18.325727\n",
       "1  ps_car_14           4268                  7.187484"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Missing values\n",
    "train_missing= train.isnull().sum()[train.isnull().sum() !=0]\n",
    "train_missing=pd.DataFrame(train_missing.reset_index())\n",
    "train_missing.rename(columns={'index':'features',0:'missing_count'},inplace=True)\n",
    "train_missing['missing_count_percentage']=((train_missing['missing_count'])/59381)*100\n",
    "train_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean imputation for Categoricval variables\n",
    "Continuos =['ps_reg_03', 'ps_car_12', 'ps_car_14']\n",
    "for col in Continuos:\n",
    "    train[col].fillna(train[col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_count_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [features, missing_count, missing_count_percentage]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Missing values\n",
    "train_missing= train.isnull().sum()[train.isnull().sum() !=0]\n",
    "train_missing=pd.DataFrame(train_missing.reset_index())\n",
    "train_missing.rename(columns={'index':'features',0:'missing_count'},inplace=True)\n",
    "train_missing['missing_count_percentage']=((train_missing['missing_count'])/59381)*100\n",
    "train_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Categorical varaible transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ps_ind_02_cat',\n",
       " 'ps_ind_04_cat',\n",
       " 'ps_ind_05_cat',\n",
       " 'ps_car_01_cat',\n",
       " 'ps_car_02_cat',\n",
       " 'ps_car_03_cat',\n",
       " 'ps_car_04_cat',\n",
       " 'ps_car_05_cat',\n",
       " 'ps_car_06_cat',\n",
       " 'ps_car_07_cat',\n",
       " 'ps_car_08_cat',\n",
       " 'ps_car_09_cat',\n",
       " 'ps_car_10_cat',\n",
       " 'ps_car_11_cat']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = [c for c in train.columns if \"_cat\" in c]\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "train = pd.get_dummies(train, columns=[i for i in categorical])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling\n",
    "\n",
    "1)Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59521, 220)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of train data\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50592, 220)\n",
      "(8929, 220)\n"
     ]
    }
   ],
   "source": [
    "#Dataset split\n",
    "train_data, test_data = train_test_split(train, test_size = 0.15)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <th>ps_ind_14</th>\n",
       "      <th>ps_ind_15</th>\n",
       "      <th>ps_ind_16_bin</th>\n",
       "      <th>ps_ind_17_bin</th>\n",
       "      <th>ps_ind_18_bin</th>\n",
       "      <th>ps_reg_01</th>\n",
       "      <th>ps_reg_02</th>\n",
       "      <th>ps_reg_03</th>\n",
       "      <th>ps_car_11</th>\n",
       "      <th>ps_car_12</th>\n",
       "      <th>ps_car_13</th>\n",
       "      <th>ps_car_14</th>\n",
       "      <th>ps_car_15</th>\n",
       "      <th>ps_calc_01</th>\n",
       "      <th>ps_calc_02</th>\n",
       "      <th>ps_calc_03</th>\n",
       "      <th>ps_calc_04</th>\n",
       "      <th>ps_calc_05</th>\n",
       "      <th>ps_calc_06</th>\n",
       "      <th>ps_calc_07</th>\n",
       "      <th>ps_calc_08</th>\n",
       "      <th>ps_calc_09</th>\n",
       "      <th>ps_calc_10</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_car_11_cat_65</th>\n",
       "      <th>ps_car_11_cat_66</th>\n",
       "      <th>ps_car_11_cat_67</th>\n",
       "      <th>ps_car_11_cat_68</th>\n",
       "      <th>ps_car_11_cat_69</th>\n",
       "      <th>ps_car_11_cat_70</th>\n",
       "      <th>ps_car_11_cat_71</th>\n",
       "      <th>ps_car_11_cat_72</th>\n",
       "      <th>ps_car_11_cat_73</th>\n",
       "      <th>ps_car_11_cat_74</th>\n",
       "      <th>ps_car_11_cat_75</th>\n",
       "      <th>ps_car_11_cat_76</th>\n",
       "      <th>ps_car_11_cat_77</th>\n",
       "      <th>ps_car_11_cat_78</th>\n",
       "      <th>ps_car_11_cat_79</th>\n",
       "      <th>ps_car_11_cat_80</th>\n",
       "      <th>ps_car_11_cat_81</th>\n",
       "      <th>ps_car_11_cat_82</th>\n",
       "      <th>ps_car_11_cat_83</th>\n",
       "      <th>ps_car_11_cat_84</th>\n",
       "      <th>ps_car_11_cat_85</th>\n",
       "      <th>ps_car_11_cat_86</th>\n",
       "      <th>ps_car_11_cat_87</th>\n",
       "      <th>ps_car_11_cat_88</th>\n",
       "      <th>ps_car_11_cat_89</th>\n",
       "      <th>ps_car_11_cat_90</th>\n",
       "      <th>ps_car_11_cat_91</th>\n",
       "      <th>ps_car_11_cat_92</th>\n",
       "      <th>ps_car_11_cat_93</th>\n",
       "      <th>ps_car_11_cat_94</th>\n",
       "      <th>ps_car_11_cat_95</th>\n",
       "      <th>ps_car_11_cat_96</th>\n",
       "      <th>ps_car_11_cat_97</th>\n",
       "      <th>ps_car_11_cat_98</th>\n",
       "      <th>ps_car_11_cat_99</th>\n",
       "      <th>ps_car_11_cat_100</th>\n",
       "      <th>ps_car_11_cat_101</th>\n",
       "      <th>ps_car_11_cat_102</th>\n",
       "      <th>ps_car_11_cat_103</th>\n",
       "      <th>ps_car_11_cat_104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>350930</th>\n",
       "      <td>876704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.083109</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.680529</td>\n",
       "      <td>0.361525</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565954</th>\n",
       "      <td>1414982</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.658501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.399750</td>\n",
       "      <td>0.768988</td>\n",
       "      <td>0.423084</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463085</th>\n",
       "      <td>1157468</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.479583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.630050</td>\n",
       "      <td>0.347275</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187143</th>\n",
       "      <td>467820</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.779824</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.649412</td>\n",
       "      <td>0.301662</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368324</th>\n",
       "      <td>920387</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.880341</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>1.264976</td>\n",
       "      <td>0.417493</td>\n",
       "      <td>3.741657</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  target        ...          ps_car_11_cat_103  ps_car_11_cat_104\n",
       "350930   876704       0        ...                          0                  0\n",
       "565954  1414982       0        ...                          0                  0\n",
       "463085  1157468       0        ...                          0                  0\n",
       "187143   467820       0        ...                          0                  0\n",
       "368324   920387       0        ...                          0                  0\n",
       "\n",
       "[5 rows x 220 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#traindata\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <th>ps_ind_14</th>\n",
       "      <th>ps_ind_15</th>\n",
       "      <th>ps_ind_16_bin</th>\n",
       "      <th>ps_ind_17_bin</th>\n",
       "      <th>ps_ind_18_bin</th>\n",
       "      <th>ps_reg_01</th>\n",
       "      <th>ps_reg_02</th>\n",
       "      <th>ps_reg_03</th>\n",
       "      <th>ps_car_11</th>\n",
       "      <th>ps_car_12</th>\n",
       "      <th>ps_car_13</th>\n",
       "      <th>ps_car_14</th>\n",
       "      <th>ps_car_15</th>\n",
       "      <th>ps_calc_01</th>\n",
       "      <th>ps_calc_02</th>\n",
       "      <th>ps_calc_03</th>\n",
       "      <th>ps_calc_04</th>\n",
       "      <th>ps_calc_05</th>\n",
       "      <th>ps_calc_06</th>\n",
       "      <th>ps_calc_07</th>\n",
       "      <th>ps_calc_08</th>\n",
       "      <th>ps_calc_09</th>\n",
       "      <th>ps_calc_10</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_car_11_cat_65</th>\n",
       "      <th>ps_car_11_cat_66</th>\n",
       "      <th>ps_car_11_cat_67</th>\n",
       "      <th>ps_car_11_cat_68</th>\n",
       "      <th>ps_car_11_cat_69</th>\n",
       "      <th>ps_car_11_cat_70</th>\n",
       "      <th>ps_car_11_cat_71</th>\n",
       "      <th>ps_car_11_cat_72</th>\n",
       "      <th>ps_car_11_cat_73</th>\n",
       "      <th>ps_car_11_cat_74</th>\n",
       "      <th>ps_car_11_cat_75</th>\n",
       "      <th>ps_car_11_cat_76</th>\n",
       "      <th>ps_car_11_cat_77</th>\n",
       "      <th>ps_car_11_cat_78</th>\n",
       "      <th>ps_car_11_cat_79</th>\n",
       "      <th>ps_car_11_cat_80</th>\n",
       "      <th>ps_car_11_cat_81</th>\n",
       "      <th>ps_car_11_cat_82</th>\n",
       "      <th>ps_car_11_cat_83</th>\n",
       "      <th>ps_car_11_cat_84</th>\n",
       "      <th>ps_car_11_cat_85</th>\n",
       "      <th>ps_car_11_cat_86</th>\n",
       "      <th>ps_car_11_cat_87</th>\n",
       "      <th>ps_car_11_cat_88</th>\n",
       "      <th>ps_car_11_cat_89</th>\n",
       "      <th>ps_car_11_cat_90</th>\n",
       "      <th>ps_car_11_cat_91</th>\n",
       "      <th>ps_car_11_cat_92</th>\n",
       "      <th>ps_car_11_cat_93</th>\n",
       "      <th>ps_car_11_cat_94</th>\n",
       "      <th>ps_car_11_cat_95</th>\n",
       "      <th>ps_car_11_cat_96</th>\n",
       "      <th>ps_car_11_cat_97</th>\n",
       "      <th>ps_car_11_cat_98</th>\n",
       "      <th>ps_car_11_cat_99</th>\n",
       "      <th>ps_car_11_cat_100</th>\n",
       "      <th>ps_car_11_cat_101</th>\n",
       "      <th>ps_car_11_cat_102</th>\n",
       "      <th>ps_car_11_cat_103</th>\n",
       "      <th>ps_car_11_cat_104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141185</th>\n",
       "      <td>352596</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.621490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316070</td>\n",
       "      <td>0.593491</td>\n",
       "      <td>0.374433</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407453</th>\n",
       "      <td>1018452</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.894180</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.849927</td>\n",
       "      <td>0.310322</td>\n",
       "      <td>3.741657</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113403</th>\n",
       "      <td>283780</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.743303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.315595</td>\n",
       "      <td>0.388204</td>\n",
       "      <td>0.374572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300038</th>\n",
       "      <td>749707</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.552834</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.605740</td>\n",
       "      <td>0.361939</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281769</th>\n",
       "      <td>704077</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.937750</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.374166</td>\n",
       "      <td>0.702240</td>\n",
       "      <td>0.390768</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  target        ...          ps_car_11_cat_103  ps_car_11_cat_104\n",
       "141185   352596       0        ...                          0                  0\n",
       "407453  1018452       0        ...                          0                  0\n",
       "113403   283780       0        ...                          0                  0\n",
       "300038   749707       0        ...                          0                  0\n",
       "281769   704077       0        ...                          0                  0\n",
       "\n",
       "[5 rows x 220 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#traindata\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50592, 218)\n",
      "(50592,)\n",
      "(8929, 218)\n",
      "(8929,)\n"
     ]
    }
   ],
   "source": [
    "#Predictor and response variables\n",
    "train_x = train_data.drop(['id', 'target'], axis=1)\n",
    "train_y = train_data['target']\n",
    "test_x = test_data.drop(['id', 'target'], axis=1)\n",
    "test_y = test_data['target']\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for normalization\n",
    "def normalization(data):\n",
    "    return (data - data.min())/(data.max() - data.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing data\n",
    "train_x = normalization(train_x)\n",
    "test_x = normalization(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <th>ps_ind_14</th>\n",
       "      <th>ps_ind_15</th>\n",
       "      <th>ps_ind_16_bin</th>\n",
       "      <th>ps_ind_17_bin</th>\n",
       "      <th>ps_ind_18_bin</th>\n",
       "      <th>ps_reg_01</th>\n",
       "      <th>ps_reg_02</th>\n",
       "      <th>ps_reg_03</th>\n",
       "      <th>ps_car_11</th>\n",
       "      <th>ps_car_12</th>\n",
       "      <th>ps_car_13</th>\n",
       "      <th>ps_car_14</th>\n",
       "      <th>ps_car_15</th>\n",
       "      <th>ps_calc_01</th>\n",
       "      <th>ps_calc_02</th>\n",
       "      <th>ps_calc_03</th>\n",
       "      <th>ps_calc_04</th>\n",
       "      <th>ps_calc_05</th>\n",
       "      <th>ps_calc_06</th>\n",
       "      <th>ps_calc_07</th>\n",
       "      <th>ps_calc_08</th>\n",
       "      <th>ps_calc_09</th>\n",
       "      <th>ps_calc_10</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_car_11_cat_65</th>\n",
       "      <th>ps_car_11_cat_66</th>\n",
       "      <th>ps_car_11_cat_67</th>\n",
       "      <th>ps_car_11_cat_68</th>\n",
       "      <th>ps_car_11_cat_69</th>\n",
       "      <th>ps_car_11_cat_70</th>\n",
       "      <th>ps_car_11_cat_71</th>\n",
       "      <th>ps_car_11_cat_72</th>\n",
       "      <th>ps_car_11_cat_73</th>\n",
       "      <th>ps_car_11_cat_74</th>\n",
       "      <th>ps_car_11_cat_75</th>\n",
       "      <th>ps_car_11_cat_76</th>\n",
       "      <th>ps_car_11_cat_77</th>\n",
       "      <th>ps_car_11_cat_78</th>\n",
       "      <th>ps_car_11_cat_79</th>\n",
       "      <th>ps_car_11_cat_80</th>\n",
       "      <th>ps_car_11_cat_81</th>\n",
       "      <th>ps_car_11_cat_82</th>\n",
       "      <th>ps_car_11_cat_83</th>\n",
       "      <th>ps_car_11_cat_84</th>\n",
       "      <th>ps_car_11_cat_85</th>\n",
       "      <th>ps_car_11_cat_86</th>\n",
       "      <th>ps_car_11_cat_87</th>\n",
       "      <th>ps_car_11_cat_88</th>\n",
       "      <th>ps_car_11_cat_89</th>\n",
       "      <th>ps_car_11_cat_90</th>\n",
       "      <th>ps_car_11_cat_91</th>\n",
       "      <th>ps_car_11_cat_92</th>\n",
       "      <th>ps_car_11_cat_93</th>\n",
       "      <th>ps_car_11_cat_94</th>\n",
       "      <th>ps_car_11_cat_95</th>\n",
       "      <th>ps_car_11_cat_96</th>\n",
       "      <th>ps_car_11_cat_97</th>\n",
       "      <th>ps_car_11_cat_98</th>\n",
       "      <th>ps_car_11_cat_99</th>\n",
       "      <th>ps_car_11_cat_100</th>\n",
       "      <th>ps_car_11_cat_101</th>\n",
       "      <th>ps_car_11_cat_102</th>\n",
       "      <th>ps_car_11_cat_103</th>\n",
       "      <th>ps_car_11_cat_104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141185</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.163360</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.155452</td>\n",
       "      <td>0.095926</td>\n",
       "      <td>0.498909</td>\n",
       "      <td>0.597614</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407453</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242872</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.155592</td>\n",
       "      <td>0.177299</td>\n",
       "      <td>0.374021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113403</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.198879</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.155029</td>\n",
       "      <td>0.030784</td>\n",
       "      <td>0.499181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300038</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.143341</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.155592</td>\n",
       "      <td>0.099813</td>\n",
       "      <td>0.474571</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281769</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.255576</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207162</td>\n",
       "      <td>0.130434</td>\n",
       "      <td>0.530731</td>\n",
       "      <td>0.845154</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ps_ind_01        ...          ps_car_11_cat_104\n",
       "141185   0.714286        ...                        0.0\n",
       "407453   0.000000        ...                        0.0\n",
       "113403   0.714286        ...                        0.0\n",
       "300038   0.142857        ...                        0.0\n",
       "281769   0.142857        ...                        0.0\n",
       "\n",
       "[5 rows x 218 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#traindata\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <th>ps_ind_14</th>\n",
       "      <th>ps_ind_15</th>\n",
       "      <th>ps_ind_16_bin</th>\n",
       "      <th>ps_ind_17_bin</th>\n",
       "      <th>ps_ind_18_bin</th>\n",
       "      <th>ps_reg_01</th>\n",
       "      <th>ps_reg_02</th>\n",
       "      <th>ps_reg_03</th>\n",
       "      <th>ps_car_11</th>\n",
       "      <th>ps_car_12</th>\n",
       "      <th>ps_car_13</th>\n",
       "      <th>ps_car_14</th>\n",
       "      <th>ps_car_15</th>\n",
       "      <th>ps_calc_01</th>\n",
       "      <th>ps_calc_02</th>\n",
       "      <th>ps_calc_03</th>\n",
       "      <th>ps_calc_04</th>\n",
       "      <th>ps_calc_05</th>\n",
       "      <th>ps_calc_06</th>\n",
       "      <th>ps_calc_07</th>\n",
       "      <th>ps_calc_08</th>\n",
       "      <th>ps_calc_09</th>\n",
       "      <th>ps_calc_10</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_car_11_cat_65</th>\n",
       "      <th>ps_car_11_cat_66</th>\n",
       "      <th>ps_car_11_cat_67</th>\n",
       "      <th>ps_car_11_cat_68</th>\n",
       "      <th>ps_car_11_cat_69</th>\n",
       "      <th>ps_car_11_cat_70</th>\n",
       "      <th>ps_car_11_cat_71</th>\n",
       "      <th>ps_car_11_cat_72</th>\n",
       "      <th>ps_car_11_cat_73</th>\n",
       "      <th>ps_car_11_cat_74</th>\n",
       "      <th>ps_car_11_cat_75</th>\n",
       "      <th>ps_car_11_cat_76</th>\n",
       "      <th>ps_car_11_cat_77</th>\n",
       "      <th>ps_car_11_cat_78</th>\n",
       "      <th>ps_car_11_cat_79</th>\n",
       "      <th>ps_car_11_cat_80</th>\n",
       "      <th>ps_car_11_cat_81</th>\n",
       "      <th>ps_car_11_cat_82</th>\n",
       "      <th>ps_car_11_cat_83</th>\n",
       "      <th>ps_car_11_cat_84</th>\n",
       "      <th>ps_car_11_cat_85</th>\n",
       "      <th>ps_car_11_cat_86</th>\n",
       "      <th>ps_car_11_cat_87</th>\n",
       "      <th>ps_car_11_cat_88</th>\n",
       "      <th>ps_car_11_cat_89</th>\n",
       "      <th>ps_car_11_cat_90</th>\n",
       "      <th>ps_car_11_cat_91</th>\n",
       "      <th>ps_car_11_cat_92</th>\n",
       "      <th>ps_car_11_cat_93</th>\n",
       "      <th>ps_car_11_cat_94</th>\n",
       "      <th>ps_car_11_cat_95</th>\n",
       "      <th>ps_car_11_cat_96</th>\n",
       "      <th>ps_car_11_cat_97</th>\n",
       "      <th>ps_car_11_cat_98</th>\n",
       "      <th>ps_car_11_cat_99</th>\n",
       "      <th>ps_car_11_cat_100</th>\n",
       "      <th>ps_car_11_cat_101</th>\n",
       "      <th>ps_car_11_cat_102</th>\n",
       "      <th>ps_car_11_cat_103</th>\n",
       "      <th>ps_car_11_cat_104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>350930</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.361515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258164</td>\n",
       "      <td>0.145188</td>\n",
       "      <td>0.513860</td>\n",
       "      <td>0.801784</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565954</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.567855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.381514</td>\n",
       "      <td>0.183510</td>\n",
       "      <td>0.643928</td>\n",
       "      <td>0.925820</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463085</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.145087</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.258164</td>\n",
       "      <td>0.123319</td>\n",
       "      <td>0.483753</td>\n",
       "      <td>0.845154</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187143</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.252755</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258164</td>\n",
       "      <td>0.131707</td>\n",
       "      <td>0.387377</td>\n",
       "      <td>0.845154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368324</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.288801</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.451611</td>\n",
       "      <td>0.398383</td>\n",
       "      <td>0.632114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ps_ind_01        ...          ps_car_11_cat_104\n",
       "350930   0.000000        ...                        0.0\n",
       "565954   0.428571        ...                        0.0\n",
       "463085   0.000000        ...                        0.0\n",
       "187143   0.285714        ...                        0.0\n",
       "368324   0.000000        ...                        0.0\n",
       "\n",
       "[5 rows x 218 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testdata\n",
    "test_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50592, 218)\n",
      "(8929, 218)\n"
     ]
    }
   ],
   "source": [
    "#Shapes of data\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)Models and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning static parameter\n",
    "nb_epoch = 20\n",
    "batch_size = 256\n",
    "input_dim = train_x.shape[1]\n",
    "hidden_dim1 = 64 \n",
    "hidden_dim2 = 32\n",
    "hidden_dim3 = 16\n",
    "learning_rate = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for auto encoder to get and fit model\n",
    "def get_fit_encoder(xs_train,xs_cv,test_x):\n",
    "    input_layer = Input(shape=(input_dim, ))\n",
    "    encoder = Dense(input_dim, activation=\"relu\",activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "    \n",
    "    encoder = Dense(hidden_dim1, activation=\"relu\")(encoder)\n",
    "    encoder = Dense(hidden_dim2, activation=\"relu\")(encoder)\n",
    "    encoder = Dense(hidden_dim3, activation=\"linear\", name=\"encoder\")(encoder)\n",
    "    \n",
    "    decoder = Dense(hidden_dim3, activation=\"relu\")(encoder)\n",
    "    decoder = Dense(hidden_dim2, activation='relu')(decoder)\n",
    "    decoder = Dense(hidden_dim1, activation='relu')(decoder)\n",
    "    decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "    \n",
    "    decoder = Dense(input_dim, activation='sigmoid')(decoder)\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "    #autoencoder.summary()\n",
    "    autoencoder.compile(optimizer='adam',\n",
    "                        loss='binary_crossentropy')\n",
    "\n",
    "    history = autoencoder.fit(x=xs_train, y=xs_train,\n",
    "                          epochs=nb_epoch,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          validation_data=(xs_cv, xs_cv),\n",
    "                          verbose=1)\n",
    "    encoder = Model(autoencoder.input, autoencoder.get_layer('encoder').output)\n",
    "    x_auto_train= encoder.predict(xs_train)\n",
    "    x_auto_cv= encoder.predict(xs_cv)\n",
    "    x_auto_test= encoder.predict(test_x)\n",
    "    return x_auto_train,x_auto_cv,x_auto_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for Neural network to get and fit model\n",
    "def get_fit_neuralnetwork(xs_encoder_train,xs_encoder_cv,xs_encoder_test,ys_train,ys_cv):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(output_dim = input_dim , init = 'normal', activation = 'relu', input_dim = 16))\n",
    "    classifier.add(Dense(output_dim = 16 , init = 'normal', activation = 'relu'))\n",
    "    classifier.add(Dense(output_dim = 8 , init = 'normal', activation = 'relu'))\n",
    "    classifier.add(Dense(output_dim = 1, init = 'normal', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    history = classifier.fit(xs_encoder_train, ys_train,\n",
    "                             batch_size=batch_size ,\n",
    "                             epochs=nb_epoch ,\n",
    "                             shuffle=True,\n",
    "                             validation_data=(xs_encoder_cv,ys_cv),\n",
    "                             verbose=1)\n",
    "    y_pred_NN = classifier.predict(xs_encoder_test, batch_size=batch_size, verbose=1)\n",
    "    return y_pred_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for State of art model to get and fit model\n",
    "def get_fit_SOA_Models(x_sampletrain,y_sampletrain,test_x):\n",
    "    model1 = LogisticRegression()\n",
    "   \n",
    "    model1.fit(x_sampletrain,y_sampletrain)\n",
    "    y_pred1 = model1.predict_proba(test_x)[:,1]\n",
    " \n",
    "    return y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for model evaluation\n",
    "def model_evaluation_roc (test_y,y_pred_NN,y_pred1):\n",
    "   \n",
    "    roc_NN = roc_auc_score(test_y,y_pred_NN)\n",
    " \n",
    "    roc_SOAM1 = roc_auc_score(test_y,y_pred1)\n",
    "\n",
    "    return roc_NN,roc_SOAM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to pass sample data to autoencoder and neural network functions\n",
    "def data_sampling(train_x, train_y, test_x, test_y):\n",
    "    accuracy_list_NN= []\n",
    "    F1_score_list_NN=[]\n",
    "    Precision_list_NN=[]\n",
    "    Recall_list_NN=[]\n",
    "    ROC_list_NN=[]\n",
    "    \n",
    "    accuracy_list_SOAM1= []\n",
    "    F1_score_list_SOAM1=[]\n",
    "    Precision_list_SOAM1=[]\n",
    "    Recall_list_SOAM1=[]\n",
    "    ROC_list_SOAM=[]\n",
    "    \n",
    "    \n",
    "    for i in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6,0.7, 0.8, 0.9, 0.99]:\n",
    "    \n",
    "        print(\"data sample {}\".format(i*100))\n",
    "        x_sampletrain, _, y_sampletrain, _ = train_test_split(train_x, train_y, stratify= train_y, train_size=i)\n",
    "        xs_train, xs_cv, ys_train, ys_cv = train_test_split(x_sampletrain, y_sampletrain, stratify=y_sampletrain, train_size=0.9)\n",
    "        xs_train.shape, xs_cv.shape, ys_train.shape, ys_cv.shape\n",
    "        xs_encoder_train,xs_encoder_cv,xs_encoder_test=get_fit_encoder(xs_train,xs_cv,test_x)\n",
    "        y_pred_NN=get_fit_neuralnetwork(xs_encoder_train,xs_encoder_cv,xs_encoder_test,ys_train,ys_cv)\n",
    "        y_pred1=get_fit_SOA_Models(x_sampletrain,y_sampletrain,test_x)\n",
    "\n",
    "        roc_NN,roc_SOAM=model_evaluation_roc(test_y,y_pred_NN,y_pred1)\n",
    "        \n",
    "        ROC_list_NN.append(roc_NN)\n",
    "        ROC_list_SOAM.append(roc_SOAM)\n",
    "       \n",
    "    return ROC_list_NN,ROC_list_SOAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data sample 10.0\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 4553 samples, validate on 506 samples\n",
      "Epoch 1/20\n",
      "4553/4553 [==============================] - 2s 388us/step - loss: 0.5590 - val_loss: 0.2725\n",
      "Epoch 2/20\n",
      "4553/4553 [==============================] - 0s 23us/step - loss: 0.2368 - val_loss: 0.2154\n",
      "Epoch 3/20\n",
      "4553/4553 [==============================] - 0s 23us/step - loss: 0.2071 - val_loss: 0.2036\n",
      "Epoch 4/20\n",
      "4553/4553 [==============================] - 0s 23us/step - loss: 0.2023 - val_loss: 0.2021\n",
      "Epoch 5/20\n",
      "4553/4553 [==============================] - 0s 23us/step - loss: 0.2014 - val_loss: 0.2016\n",
      "Epoch 6/20\n",
      "4553/4553 [==============================] - 0s 22us/step - loss: 0.2010 - val_loss: 0.2014\n",
      "Epoch 7/20\n",
      "4553/4553 [==============================] - 0s 22us/step - loss: 0.2008 - val_loss: 0.2013\n",
      "Epoch 8/20\n",
      "4553/4553 [==============================] - 0s 23us/step - loss: 0.2006 - val_loss: 0.2011\n",
      "Epoch 9/20\n",
      "4553/4553 [==============================] - 0s 22us/step - loss: 0.2004 - val_loss: 0.2009\n",
      "Epoch 10/20\n",
      "4553/4553 [==============================] - 0s 23us/step - loss: 0.2003 - val_loss: 0.2008\n",
      "Epoch 11/20\n",
      "4553/4553 [==============================] - 0s 23us/step - loss: 0.2002 - val_loss: 0.2008\n",
      "Epoch 12/20\n",
      "4553/4553 [==============================] - 0s 23us/step - loss: 0.2001 - val_loss: 0.2006\n",
      "Epoch 13/20\n",
      "4553/4553 [==============================] - 0s 23us/step - loss: 0.1999 - val_loss: 0.2005\n",
      "Epoch 14/20\n",
      "4553/4553 [==============================] - 0s 22us/step - loss: 0.1996 - val_loss: 0.1999\n",
      "Epoch 15/20\n",
      "4553/4553 [==============================] - 0s 23us/step - loss: 0.1984 - val_loss: 0.1975\n",
      "Epoch 16/20\n",
      "4553/4553 [==============================] - 0s 22us/step - loss: 0.1947 - val_loss: 0.1932\n",
      "Epoch 17/20\n",
      "4553/4553 [==============================] - 0s 23us/step - loss: 0.1922 - val_loss: 0.1917\n",
      "Epoch 18/20\n",
      "4553/4553 [==============================] - 0s 23us/step - loss: 0.1910 - val_loss: 0.1908\n",
      "Epoch 19/20\n",
      "4553/4553 [==============================] - 0s 22us/step - loss: 0.1901 - val_loss: 0.1900\n",
      "Epoch 20/20\n",
      "4553/4553 [==============================] - 0s 22us/step - loss: 0.1892 - val_loss: 0.1892\n",
      "Train on 4553 samples, validate on 506 samples\n",
      "Epoch 1/20\n",
      "4553/4553 [==============================] - 0s 101us/step - loss: 0.6706 - acc: 0.9635 - val_loss: 0.6323 - val_acc: 0.9625\n",
      "Epoch 2/20\n",
      "4553/4553 [==============================] - 0s 14us/step - loss: 0.5440 - acc: 0.9635 - val_loss: 0.3992 - val_acc: 0.9625\n",
      "Epoch 3/20\n",
      "4553/4553 [==============================] - 0s 14us/step - loss: 0.2603 - acc: 0.9635 - val_loss: 0.1624 - val_acc: 0.9625\n",
      "Epoch 4/20\n",
      "4553/4553 [==============================] - 0s 15us/step - loss: 0.1594 - acc: 0.9635 - val_loss: 0.1647 - val_acc: 0.9625\n",
      "Epoch 5/20\n",
      "4553/4553 [==============================] - 0s 14us/step - loss: 0.1581 - acc: 0.9635 - val_loss: 0.1595 - val_acc: 0.9625\n",
      "Epoch 6/20\n",
      "4553/4553 [==============================] - 0s 14us/step - loss: 0.1561 - acc: 0.9635 - val_loss: 0.1594 - val_acc: 0.9625\n",
      "Epoch 7/20\n",
      "4553/4553 [==============================] - 0s 14us/step - loss: 0.1561 - acc: 0.9635 - val_loss: 0.1593 - val_acc: 0.9625\n",
      "Epoch 8/20\n",
      "4553/4553 [==============================] - 0s 14us/step - loss: 0.1559 - acc: 0.9635 - val_loss: 0.1593 - val_acc: 0.9625\n",
      "Epoch 9/20\n",
      "4553/4553 [==============================] - 0s 14us/step - loss: 0.1561 - acc: 0.9635 - val_loss: 0.1592 - val_acc: 0.9625\n",
      "Epoch 10/20\n",
      "4553/4553 [==============================] - 0s 14us/step - loss: 0.1559 - acc: 0.9635 - val_loss: 0.1593 - val_acc: 0.9625\n",
      "Epoch 11/20\n",
      "4553/4553 [==============================] - 0s 14us/step - loss: 0.1559 - acc: 0.9635 - val_loss: 0.1591 - val_acc: 0.9625\n",
      "Epoch 12/20\n",
      "4553/4553 [==============================] - 0s 14us/step - loss: 0.1558 - acc: 0.9635 - val_loss: 0.1592 - val_acc: 0.9625\n",
      "Epoch 13/20\n",
      "4553/4553 [==============================] - 0s 14us/step - loss: 0.1559 - acc: 0.9635 - val_loss: 0.1591 - val_acc: 0.9625\n",
      "Epoch 14/20\n",
      "4553/4553 [==============================] - 0s 14us/step - loss: 0.1558 - acc: 0.9635 - val_loss: 0.1591 - val_acc: 0.9625\n",
      "Epoch 15/20\n",
      "4553/4553 [==============================] - 0s 14us/step - loss: 0.1558 - acc: 0.9635 - val_loss: 0.1591 - val_acc: 0.9625\n",
      "Epoch 16/20\n",
      "4553/4553 [==============================] - 0s 14us/step - loss: 0.1558 - acc: 0.9635 - val_loss: 0.1590 - val_acc: 0.9625\n",
      "Epoch 17/20\n",
      "4553/4553 [==============================] - 0s 14us/step - loss: 0.1559 - acc: 0.9635 - val_loss: 0.1591 - val_acc: 0.9625\n",
      "Epoch 18/20\n",
      "4553/4553 [==============================] - 0s 14us/step - loss: 0.1559 - acc: 0.9635 - val_loss: 0.1590 - val_acc: 0.9625\n",
      "Epoch 19/20\n",
      "4553/4553 [==============================] - 0s 14us/step - loss: 0.1557 - acc: 0.9635 - val_loss: 0.1590 - val_acc: 0.9625\n",
      "Epoch 20/20\n",
      "4553/4553 [==============================] - 0s 14us/step - loss: 0.1558 - acc: 0.9635 - val_loss: 0.1591 - val_acc: 0.9625\n",
      "8929/8929 [==============================] - 0s 10us/step\n",
      "data sample 20.0\n",
      "Train on 9106 samples, validate on 1012 samples\n",
      "Epoch 1/20\n",
      "9106/9106 [==============================] - 1s 104us/step - loss: 0.3929 - val_loss: 0.2149\n",
      "Epoch 2/20\n",
      "9106/9106 [==============================] - 0s 26us/step - loss: 0.2048 - val_loss: 0.2022\n",
      "Epoch 3/20\n",
      "9106/9106 [==============================] - 0s 26us/step - loss: 0.2015 - val_loss: 0.2014\n",
      "Epoch 4/20\n",
      "9106/9106 [==============================] - 0s 25us/step - loss: 0.2009 - val_loss: 0.2009\n",
      "Epoch 5/20\n",
      "9106/9106 [==============================] - 0s 28us/step - loss: 0.2004 - val_loss: 0.2004\n",
      "Epoch 6/20\n",
      "9106/9106 [==============================] - 0s 26us/step - loss: 0.1994 - val_loss: 0.1983\n",
      "Epoch 7/20\n",
      "9106/9106 [==============================] - 0s 26us/step - loss: 0.1956 - val_loss: 0.1937\n",
      "Epoch 8/20\n",
      "9106/9106 [==============================] - 0s 26us/step - loss: 0.1909 - val_loss: 0.1875\n",
      "Epoch 9/20\n",
      "9106/9106 [==============================] - 0s 25us/step - loss: 0.1848 - val_loss: 0.1833\n",
      "Epoch 10/20\n",
      "9106/9106 [==============================] - 0s 25us/step - loss: 0.1810 - val_loss: 0.1788\n",
      "Epoch 11/20\n",
      "9106/9106 [==============================] - 0s 25us/step - loss: 0.1759 - val_loss: 0.1741\n",
      "Epoch 12/20\n",
      "9106/9106 [==============================] - 0s 26us/step - loss: 0.1715 - val_loss: 0.1705\n",
      "Epoch 13/20\n",
      "9106/9106 [==============================] - 0s 25us/step - loss: 0.1676 - val_loss: 0.1667\n",
      "Epoch 14/20\n",
      "9106/9106 [==============================] - 0s 25us/step - loss: 0.1633 - val_loss: 0.1626\n",
      "Epoch 15/20\n",
      "9106/9106 [==============================] - 0s 24us/step - loss: 0.1588 - val_loss: 0.1577\n",
      "Epoch 16/20\n",
      "9106/9106 [==============================] - 0s 26us/step - loss: 0.1535 - val_loss: 0.1523\n",
      "Epoch 17/20\n",
      "9106/9106 [==============================] - 0s 29us/step - loss: 0.1487 - val_loss: 0.1484\n",
      "Epoch 18/20\n",
      "9106/9106 [==============================] - 0s 29us/step - loss: 0.1454 - val_loss: 0.1451\n",
      "Epoch 19/20\n",
      "9106/9106 [==============================] - 0s 30us/step - loss: 0.1416 - val_loss: 0.1416\n",
      "Epoch 20/20\n",
      "9106/9106 [==============================] - 0s 30us/step - loss: 0.1382 - val_loss: 0.1381\n",
      "Train on 9106 samples, validate on 1012 samples\n",
      "Epoch 1/20\n",
      "9106/9106 [==============================] - 1s 87us/step - loss: 0.5650 - acc: 0.9557 - val_loss: 0.2639 - val_acc: 0.9634\n",
      "Epoch 2/20\n",
      "9106/9106 [==============================] - 0s 17us/step - loss: 0.1725 - acc: 0.9635 - val_loss: 0.1565 - val_acc: 0.9634\n",
      "Epoch 3/20\n",
      "9106/9106 [==============================] - 0s 16us/step - loss: 0.1568 - acc: 0.9635 - val_loss: 0.1557 - val_acc: 0.9634\n",
      "Epoch 4/20\n",
      "9106/9106 [==============================] - 0s 17us/step - loss: 0.1569 - acc: 0.9635 - val_loss: 0.1555 - val_acc: 0.9634\n",
      "Epoch 5/20\n",
      "9106/9106 [==============================] - 0s 16us/step - loss: 0.1566 - acc: 0.9635 - val_loss: 0.1561 - val_acc: 0.9634\n",
      "Epoch 6/20\n",
      "9106/9106 [==============================] - 0s 17us/step - loss: 0.1571 - acc: 0.9635 - val_loss: 0.1553 - val_acc: 0.9634\n",
      "Epoch 7/20\n",
      "9106/9106 [==============================] - 0s 16us/step - loss: 0.1563 - acc: 0.9635 - val_loss: 0.1552 - val_acc: 0.9634\n",
      "Epoch 8/20\n",
      "9106/9106 [==============================] - 0s 17us/step - loss: 0.1561 - acc: 0.9635 - val_loss: 0.1550 - val_acc: 0.9634\n",
      "Epoch 9/20\n",
      "9106/9106 [==============================] - 0s 16us/step - loss: 0.1560 - acc: 0.9635 - val_loss: 0.1550 - val_acc: 0.9634\n",
      "Epoch 10/20\n",
      "9106/9106 [==============================] - 0s 16us/step - loss: 0.1561 - acc: 0.9635 - val_loss: 0.1550 - val_acc: 0.9634\n",
      "Epoch 11/20\n",
      "9106/9106 [==============================] - 0s 16us/step - loss: 0.1569 - acc: 0.9635 - val_loss: 0.1563 - val_acc: 0.9634\n",
      "Epoch 12/20\n",
      "9106/9106 [==============================] - 0s 16us/step - loss: 0.1560 - acc: 0.9635 - val_loss: 0.1547 - val_acc: 0.9634\n",
      "Epoch 13/20\n",
      "9106/9106 [==============================] - 0s 17us/step - loss: 0.1559 - acc: 0.9635 - val_loss: 0.1546 - val_acc: 0.9634\n",
      "Epoch 14/20\n",
      "9106/9106 [==============================] - 0s 16us/step - loss: 0.1560 - acc: 0.9635 - val_loss: 0.1550 - val_acc: 0.9634\n",
      "Epoch 15/20\n",
      "9106/9106 [==============================] - 0s 16us/step - loss: 0.1561 - acc: 0.9635 - val_loss: 0.1546 - val_acc: 0.9634\n",
      "Epoch 16/20\n",
      "9106/9106 [==============================] - 0s 15us/step - loss: 0.1558 - acc: 0.9635 - val_loss: 0.1546 - val_acc: 0.9634\n",
      "Epoch 17/20\n",
      "9106/9106 [==============================] - 0s 14us/step - loss: 0.1559 - acc: 0.9635 - val_loss: 0.1543 - val_acc: 0.9634\n",
      "Epoch 18/20\n",
      "9106/9106 [==============================] - 0s 14us/step - loss: 0.1565 - acc: 0.9635 - val_loss: 0.1549 - val_acc: 0.9634\n",
      "Epoch 19/20\n",
      "9106/9106 [==============================] - 0s 14us/step - loss: 0.1569 - acc: 0.9635 - val_loss: 0.1555 - val_acc: 0.9634\n",
      "Epoch 20/20\n",
      "9106/9106 [==============================] - 0s 14us/step - loss: 0.1558 - acc: 0.9635 - val_loss: 0.1541 - val_acc: 0.9634\n",
      "8929/8929 [==============================] - 0s 18us/step\n",
      "data sample 30.0\n",
      "Train on 13659 samples, validate on 1518 samples\n",
      "Epoch 1/20\n",
      "13659/13659 [==============================] - 1s 92us/step - loss: 0.3519 - val_loss: 0.2031\n",
      "Epoch 2/20\n",
      "13659/13659 [==============================] - 0s 28us/step - loss: 0.2020 - val_loss: 0.2010\n",
      "Epoch 3/20\n",
      "13659/13659 [==============================] - 0s 27us/step - loss: 0.2010 - val_loss: 0.2003\n",
      "Epoch 4/20\n",
      "13659/13659 [==============================] - 0s 27us/step - loss: 0.1997 - val_loss: 0.1966\n",
      "Epoch 5/20\n",
      "13659/13659 [==============================] - 0s 27us/step - loss: 0.1938 - val_loss: 0.1921\n",
      "Epoch 6/20\n",
      "13659/13659 [==============================] - 0s 27us/step - loss: 0.1907 - val_loss: 0.1893\n",
      "Epoch 7/20\n",
      "13659/13659 [==============================] - 0s 27us/step - loss: 0.1874 - val_loss: 0.1845\n",
      "Epoch 8/20\n",
      "13659/13659 [==============================] - 0s 27us/step - loss: 0.1811 - val_loss: 0.1789\n",
      "Epoch 9/20\n",
      "13659/13659 [==============================] - 0s 28us/step - loss: 0.1772 - val_loss: 0.1757\n",
      "Epoch 10/20\n",
      "13659/13659 [==============================] - 0s 27us/step - loss: 0.1740 - val_loss: 0.1716\n",
      "Epoch 11/20\n",
      "13659/13659 [==============================] - 0s 28us/step - loss: 0.1686 - val_loss: 0.1669\n",
      "Epoch 12/20\n",
      "13659/13659 [==============================] - 0s 27us/step - loss: 0.1652 - val_loss: 0.1641\n",
      "Epoch 13/20\n",
      "13659/13659 [==============================] - 0s 28us/step - loss: 0.1621 - val_loss: 0.1610\n",
      "Epoch 14/20\n",
      "13659/13659 [==============================] - 0s 27us/step - loss: 0.1587 - val_loss: 0.1578\n",
      "Epoch 15/20\n",
      "13659/13659 [==============================] - 0s 28us/step - loss: 0.1560 - val_loss: 0.1557\n",
      "Epoch 16/20\n",
      "13659/13659 [==============================] - 0s 27us/step - loss: 0.1538 - val_loss: 0.1540\n",
      "Epoch 17/20\n",
      "13659/13659 [==============================] - 0s 27us/step - loss: 0.1519 - val_loss: 0.1520\n",
      "Epoch 18/20\n",
      "13659/13659 [==============================] - 0s 27us/step - loss: 0.1502 - val_loss: 0.1508\n",
      "Epoch 19/20\n",
      "13659/13659 [==============================] - 0s 27us/step - loss: 0.1486 - val_loss: 0.1488\n",
      "Epoch 20/20\n",
      "13659/13659 [==============================] - 0s 27us/step - loss: 0.1468 - val_loss: 0.1473\n",
      "Train on 13659 samples, validate on 1518 samples\n",
      "Epoch 1/20\n",
      "13659/13659 [==============================] - 1s 68us/step - loss: 0.4180 - acc: 0.9635 - val_loss: 0.1735 - val_acc: 0.9638\n",
      "Epoch 2/20\n",
      "13659/13659 [==============================] - 0s 14us/step - loss: 0.1634 - acc: 0.9635 - val_loss: 0.1621 - val_acc: 0.9638\n",
      "Epoch 3/20\n",
      "13659/13659 [==============================] - 0s 14us/step - loss: 0.1607 - acc: 0.9635 - val_loss: 0.1612 - val_acc: 0.9638\n",
      "Epoch 4/20\n",
      "13659/13659 [==============================] - 0s 14us/step - loss: 0.1604 - acc: 0.9635 - val_loss: 0.1612 - val_acc: 0.9638\n",
      "Epoch 5/20\n",
      "13659/13659 [==============================] - 0s 15us/step - loss: 0.1597 - acc: 0.9635 - val_loss: 0.1607 - val_acc: 0.9638\n",
      "Epoch 6/20\n",
      "13659/13659 [==============================] - 0s 15us/step - loss: 0.1590 - acc: 0.9635 - val_loss: 0.1597 - val_acc: 0.9638\n",
      "Epoch 7/20\n",
      "13659/13659 [==============================] - 0s 14us/step - loss: 0.1591 - acc: 0.9635 - val_loss: 0.1593 - val_acc: 0.9638\n",
      "Epoch 8/20\n",
      "13659/13659 [==============================] - 0s 14us/step - loss: 0.1583 - acc: 0.9635 - val_loss: 0.1598 - val_acc: 0.9638\n",
      "Epoch 9/20\n",
      "13659/13659 [==============================] - 0s 14us/step - loss: 0.1583 - acc: 0.9635 - val_loss: 0.1584 - val_acc: 0.9638\n",
      "Epoch 10/20\n",
      "13659/13659 [==============================] - 0s 14us/step - loss: 0.1581 - acc: 0.9635 - val_loss: 0.1581 - val_acc: 0.9638\n",
      "Epoch 11/20\n",
      "13659/13659 [==============================] - 0s 15us/step - loss: 0.1577 - acc: 0.9635 - val_loss: 0.1594 - val_acc: 0.9638\n",
      "Epoch 12/20\n",
      "13659/13659 [==============================] - 0s 14us/step - loss: 0.1578 - acc: 0.9635 - val_loss: 0.1580 - val_acc: 0.9638\n",
      "Epoch 13/20\n",
      "13659/13659 [==============================] - 0s 14us/step - loss: 0.1575 - acc: 0.9635 - val_loss: 0.1575 - val_acc: 0.9638\n",
      "Epoch 14/20\n",
      "13659/13659 [==============================] - 0s 15us/step - loss: 0.1573 - acc: 0.9635 - val_loss: 0.1582 - val_acc: 0.9638\n",
      "Epoch 15/20\n",
      "13659/13659 [==============================] - 0s 14us/step - loss: 0.1574 - acc: 0.9635 - val_loss: 0.1571 - val_acc: 0.9638\n",
      "Epoch 16/20\n",
      "13659/13659 [==============================] - 0s 14us/step - loss: 0.1572 - acc: 0.9635 - val_loss: 0.1568 - val_acc: 0.9638\n",
      "Epoch 17/20\n",
      "13659/13659 [==============================] - 0s 14us/step - loss: 0.1568 - acc: 0.9635 - val_loss: 0.1570 - val_acc: 0.9638\n",
      "Epoch 18/20\n",
      "13659/13659 [==============================] - 0s 15us/step - loss: 0.1566 - acc: 0.9635 - val_loss: 0.1591 - val_acc: 0.9638\n",
      "Epoch 19/20\n",
      "13659/13659 [==============================] - 0s 15us/step - loss: 0.1572 - acc: 0.9635 - val_loss: 0.1569 - val_acc: 0.9638\n",
      "Epoch 20/20\n",
      "13659/13659 [==============================] - 0s 14us/step - loss: 0.1563 - acc: 0.9635 - val_loss: 0.1567 - val_acc: 0.9638\n",
      "8929/8929 [==============================] - 0s 26us/step\n",
      "data sample 40.0\n",
      "Train on 18212 samples, validate on 2024 samples\n",
      "Epoch 1/20\n",
      "18212/18212 [==============================] - 2s 89us/step - loss: 0.3000 - val_loss: 0.2022\n",
      "Epoch 2/20\n",
      "18212/18212 [==============================] - 1s 30us/step - loss: 0.2011 - val_loss: 0.2012\n",
      "Epoch 3/20\n",
      "18212/18212 [==============================] - 1s 31us/step - loss: 0.1995 - val_loss: 0.1963\n",
      "Epoch 4/20\n",
      "18212/18212 [==============================] - 1s 29us/step - loss: 0.1879 - val_loss: 0.1831\n",
      "Epoch 5/20\n",
      "18212/18212 [==============================] - 1s 29us/step - loss: 0.1802 - val_loss: 0.1797\n",
      "Epoch 6/20\n",
      "18212/18212 [==============================] - 1s 29us/step - loss: 0.1768 - val_loss: 0.1755\n",
      "Epoch 7/20\n",
      "18212/18212 [==============================] - 1s 28us/step - loss: 0.1691 - val_loss: 0.1636\n",
      "Epoch 8/20\n",
      "18212/18212 [==============================] - 1s 30us/step - loss: 0.1582 - val_loss: 0.1554\n",
      "Epoch 9/20\n",
      "18212/18212 [==============================] - 1s 29us/step - loss: 0.1510 - val_loss: 0.1493\n",
      "Epoch 10/20\n",
      "18212/18212 [==============================] - 1s 30us/step - loss: 0.1464 - val_loss: 0.1464\n",
      "Epoch 11/20\n",
      "18212/18212 [==============================] - 1s 28us/step - loss: 0.1430 - val_loss: 0.1432\n",
      "Epoch 12/20\n",
      "18212/18212 [==============================] - 1s 29us/step - loss: 0.1403 - val_loss: 0.1409\n",
      "Epoch 13/20\n",
      "18212/18212 [==============================] - 1s 29us/step - loss: 0.1378 - val_loss: 0.1383\n",
      "Epoch 14/20\n",
      "18212/18212 [==============================] - 1s 29us/step - loss: 0.1353 - val_loss: 0.1358\n",
      "Epoch 15/20\n",
      "18212/18212 [==============================] - 1s 29us/step - loss: 0.1326 - val_loss: 0.1336\n",
      "Epoch 16/20\n",
      "18212/18212 [==============================] - 1s 29us/step - loss: 0.1303 - val_loss: 0.1326\n",
      "Epoch 17/20\n",
      "18212/18212 [==============================] - 1s 29us/step - loss: 0.1288 - val_loss: 0.1299\n",
      "Epoch 18/20\n",
      "18212/18212 [==============================] - 1s 29us/step - loss: 0.1274 - val_loss: 0.1308\n",
      "Epoch 19/20\n",
      "18212/18212 [==============================] - 1s 29us/step - loss: 0.1263 - val_loss: 0.1278\n",
      "Epoch 20/20\n",
      "18212/18212 [==============================] - 1s 29us/step - loss: 0.1249 - val_loss: 0.1268\n",
      "Train on 18212 samples, validate on 2024 samples\n",
      "Epoch 1/20\n",
      "18212/18212 [==============================] - 1s 68us/step - loss: 0.4131 - acc: 0.9600 - val_loss: 0.1669 - val_acc: 0.9634\n",
      "Epoch 2/20\n",
      "18212/18212 [==============================] - 0s 15us/step - loss: 0.1617 - acc: 0.9635 - val_loss: 0.1602 - val_acc: 0.9634\n",
      "Epoch 3/20\n",
      "18212/18212 [==============================] - 0s 15us/step - loss: 0.1605 - acc: 0.9635 - val_loss: 0.1599 - val_acc: 0.9634\n",
      "Epoch 4/20\n",
      "18212/18212 [==============================] - 0s 15us/step - loss: 0.1601 - acc: 0.9635 - val_loss: 0.1598 - val_acc: 0.9634\n",
      "Epoch 5/20\n",
      "18212/18212 [==============================] - 0s 16us/step - loss: 0.1598 - acc: 0.9635 - val_loss: 0.1598 - val_acc: 0.9634\n",
      "Epoch 6/20\n",
      "18212/18212 [==============================] - 0s 17us/step - loss: 0.1598 - acc: 0.9635 - val_loss: 0.1601 - val_acc: 0.9634\n",
      "Epoch 7/20\n",
      "18212/18212 [==============================] - 0s 17us/step - loss: 0.1598 - acc: 0.9635 - val_loss: 0.1593 - val_acc: 0.9634\n",
      "Epoch 8/20\n",
      "18212/18212 [==============================] - 0s 17us/step - loss: 0.1588 - acc: 0.9635 - val_loss: 0.1590 - val_acc: 0.9634\n",
      "Epoch 9/20\n",
      "18212/18212 [==============================] - 0s 17us/step - loss: 0.1584 - acc: 0.9635 - val_loss: 0.1597 - val_acc: 0.9634\n",
      "Epoch 10/20\n",
      "18212/18212 [==============================] - 0s 17us/step - loss: 0.1580 - acc: 0.9635 - val_loss: 0.1584 - val_acc: 0.9634\n",
      "Epoch 11/20\n",
      "18212/18212 [==============================] - 0s 17us/step - loss: 0.1575 - acc: 0.9635 - val_loss: 0.1582 - val_acc: 0.9634\n",
      "Epoch 12/20\n",
      "18212/18212 [==============================] - 0s 17us/step - loss: 0.1573 - acc: 0.9635 - val_loss: 0.1577 - val_acc: 0.9634\n",
      "Epoch 13/20\n",
      "18212/18212 [==============================] - 0s 17us/step - loss: 0.1567 - acc: 0.9635 - val_loss: 0.1577 - val_acc: 0.9634\n",
      "Epoch 14/20\n",
      "18212/18212 [==============================] - 0s 17us/step - loss: 0.1561 - acc: 0.9635 - val_loss: 0.1577 - val_acc: 0.9634\n",
      "Epoch 15/20\n",
      "18212/18212 [==============================] - 0s 17us/step - loss: 0.1560 - acc: 0.9635 - val_loss: 0.1566 - val_acc: 0.9634\n",
      "Epoch 16/20\n",
      "18212/18212 [==============================] - 0s 17us/step - loss: 0.1563 - acc: 0.9635 - val_loss: 0.1563 - val_acc: 0.9634\n",
      "Epoch 17/20\n",
      "18212/18212 [==============================] - 0s 17us/step - loss: 0.1553 - acc: 0.9635 - val_loss: 0.1558 - val_acc: 0.9634\n",
      "Epoch 18/20\n",
      "18212/18212 [==============================] - 0s 17us/step - loss: 0.1552 - acc: 0.9635 - val_loss: 0.1564 - val_acc: 0.9634\n",
      "Epoch 19/20\n",
      "18212/18212 [==============================] - 0s 16us/step - loss: 0.1554 - acc: 0.9635 - val_loss: 0.1563 - val_acc: 0.9634\n",
      "Epoch 20/20\n",
      "18212/18212 [==============================] - 0s 17us/step - loss: 0.1548 - acc: 0.9635 - val_loss: 0.1571 - val_acc: 0.9634\n",
      "8929/8929 [==============================] - 0s 39us/step\n",
      "data sample 50.0\n",
      "Train on 22766 samples, validate on 2530 samples\n",
      "Epoch 1/20\n",
      "22766/22766 [==============================] - 2s 97us/step - loss: 0.2671 - val_loss: 0.2013\n",
      "Epoch 2/20\n",
      "22766/22766 [==============================] - 1s 33us/step - loss: 0.2004 - val_loss: 0.1993\n",
      "Epoch 3/20\n",
      "22766/22766 [==============================] - 1s 30us/step - loss: 0.1936 - val_loss: 0.1899\n",
      "Epoch 4/20\n",
      "22766/22766 [==============================] - 1s 30us/step - loss: 0.1850 - val_loss: 0.1782\n",
      "Epoch 5/20\n",
      "22766/22766 [==============================] - 1s 30us/step - loss: 0.1717 - val_loss: 0.1677\n",
      "Epoch 6/20\n",
      "22766/22766 [==============================] - 1s 31us/step - loss: 0.1626 - val_loss: 0.1590\n",
      "Epoch 7/20\n",
      "22766/22766 [==============================] - 1s 30us/step - loss: 0.1564 - val_loss: 0.1537\n",
      "Epoch 8/20\n",
      "22766/22766 [==============================] - 1s 30us/step - loss: 0.1507 - val_loss: 0.1478\n",
      "Epoch 9/20\n",
      "22766/22766 [==============================] - 1s 30us/step - loss: 0.1443 - val_loss: 0.1414\n",
      "Epoch 10/20\n",
      "22766/22766 [==============================] - 1s 30us/step - loss: 0.1391 - val_loss: 0.1372\n",
      "Epoch 11/20\n",
      "22766/22766 [==============================] - 1s 30us/step - loss: 0.1337 - val_loss: 0.1315\n",
      "Epoch 12/20\n",
      "22766/22766 [==============================] - 1s 30us/step - loss: 0.1290 - val_loss: 0.1276\n",
      "Epoch 13/20\n",
      "22766/22766 [==============================] - 1s 30us/step - loss: 0.1254 - val_loss: 0.1243\n",
      "Epoch 14/20\n",
      "22766/22766 [==============================] - 1s 31us/step - loss: 0.1223 - val_loss: 0.1221\n",
      "Epoch 15/20\n",
      "22766/22766 [==============================] - 1s 30us/step - loss: 0.1198 - val_loss: 0.1194\n",
      "Epoch 16/20\n",
      "22766/22766 [==============================] - 1s 30us/step - loss: 0.1173 - val_loss: 0.1170\n",
      "Epoch 17/20\n",
      "22766/22766 [==============================] - 1s 30us/step - loss: 0.1151 - val_loss: 0.1152\n",
      "Epoch 18/20\n",
      "22766/22766 [==============================] - 1s 30us/step - loss: 0.1133 - val_loss: 0.1134\n",
      "Epoch 19/20\n",
      "22766/22766 [==============================] - 1s 30us/step - loss: 0.1113 - val_loss: 0.1123\n",
      "Epoch 20/20\n",
      "22766/22766 [==============================] - 1s 30us/step - loss: 0.1095 - val_loss: 0.1097\n",
      "Train on 22766 samples, validate on 2530 samples\n",
      "Epoch 1/20\n",
      "22766/22766 [==============================] - 2s 67us/step - loss: 0.3417 - acc: 0.9520 - val_loss: 0.1720 - val_acc: 0.9636\n",
      "Epoch 2/20\n",
      "22766/22766 [==============================] - 0s 15us/step - loss: 0.1638 - acc: 0.9635 - val_loss: 0.1685 - val_acc: 0.9636\n",
      "Epoch 3/20\n",
      "22766/22766 [==============================] - 0s 15us/step - loss: 0.1615 - acc: 0.9635 - val_loss: 0.1653 - val_acc: 0.9636\n",
      "Epoch 4/20\n",
      "22766/22766 [==============================] - 0s 15us/step - loss: 0.1599 - acc: 0.9635 - val_loss: 0.1630 - val_acc: 0.9636\n",
      "Epoch 5/20\n",
      "22766/22766 [==============================] - 0s 15us/step - loss: 0.1592 - acc: 0.9635 - val_loss: 0.1627 - val_acc: 0.9636\n",
      "Epoch 6/20\n",
      "22766/22766 [==============================] - 0s 15us/step - loss: 0.1583 - acc: 0.9635 - val_loss: 0.1610 - val_acc: 0.9636\n",
      "Epoch 7/20\n",
      "22766/22766 [==============================] - 0s 15us/step - loss: 0.1580 - acc: 0.9635 - val_loss: 0.1612 - val_acc: 0.9636\n",
      "Epoch 8/20\n",
      "22766/22766 [==============================] - 0s 15us/step - loss: 0.1582 - acc: 0.9635 - val_loss: 0.1629 - val_acc: 0.9636\n",
      "Epoch 9/20\n",
      "22766/22766 [==============================] - 0s 15us/step - loss: 0.1580 - acc: 0.9635 - val_loss: 0.1600 - val_acc: 0.9636\n",
      "Epoch 10/20\n",
      "22766/22766 [==============================] - 0s 15us/step - loss: 0.1576 - acc: 0.9635 - val_loss: 0.1600 - val_acc: 0.9636\n",
      "Epoch 11/20\n",
      "22766/22766 [==============================] - 0s 15us/step - loss: 0.1575 - acc: 0.9635 - val_loss: 0.1604 - val_acc: 0.9636\n",
      "Epoch 12/20\n",
      "22766/22766 [==============================] - 0s 15us/step - loss: 0.1575 - acc: 0.9635 - val_loss: 0.1605 - val_acc: 0.9636\n",
      "Epoch 13/20\n",
      "22766/22766 [==============================] - 0s 15us/step - loss: 0.1573 - acc: 0.9635 - val_loss: 0.1606 - val_acc: 0.9636\n",
      "Epoch 14/20\n",
      "22766/22766 [==============================] - 0s 15us/step - loss: 0.1573 - acc: 0.9635 - val_loss: 0.1595 - val_acc: 0.9636\n",
      "Epoch 15/20\n",
      "22766/22766 [==============================] - 0s 15us/step - loss: 0.1573 - acc: 0.9635 - val_loss: 0.1602 - val_acc: 0.9636\n",
      "Epoch 16/20\n",
      "22766/22766 [==============================] - 0s 15us/step - loss: 0.1573 - acc: 0.9635 - val_loss: 0.1599 - val_acc: 0.9636\n",
      "Epoch 17/20\n",
      "22766/22766 [==============================] - 0s 15us/step - loss: 0.1573 - acc: 0.9635 - val_loss: 0.1597 - val_acc: 0.9636\n",
      "Epoch 18/20\n",
      "22766/22766 [==============================] - 0s 15us/step - loss: 0.1572 - acc: 0.9635 - val_loss: 0.1591 - val_acc: 0.9636\n",
      "Epoch 19/20\n",
      "22766/22766 [==============================] - 0s 15us/step - loss: 0.1569 - acc: 0.9635 - val_loss: 0.1595 - val_acc: 0.9636\n",
      "Epoch 20/20\n",
      "22766/22766 [==============================] - 0s 15us/step - loss: 0.1568 - acc: 0.9635 - val_loss: 0.1593 - val_acc: 0.9636\n",
      "8929/8929 [==============================] - 0s 44us/step\n",
      "data sample 60.0\n",
      "Train on 27319 samples, validate on 3036 samples\n",
      "Epoch 1/20\n",
      "27319/27319 [==============================] - 2s 88us/step - loss: 0.2699 - val_loss: 0.2013\n",
      "Epoch 2/20\n",
      "27319/27319 [==============================] - 1s 32us/step - loss: 0.2004 - val_loss: 0.1983\n",
      "Epoch 3/20\n",
      "27319/27319 [==============================] - 1s 32us/step - loss: 0.1899 - val_loss: 0.1822\n",
      "Epoch 4/20\n",
      "27319/27319 [==============================] - 1s 31us/step - loss: 0.1742 - val_loss: 0.1653\n",
      "Epoch 5/20\n",
      "27319/27319 [==============================] - 1s 32us/step - loss: 0.1622 - val_loss: 0.1582\n",
      "Epoch 6/20\n",
      "27319/27319 [==============================] - 1s 32us/step - loss: 0.1539 - val_loss: 0.1493\n",
      "Epoch 7/20\n",
      "27319/27319 [==============================] - 1s 32us/step - loss: 0.1470 - val_loss: 0.1446\n",
      "Epoch 8/20\n",
      "27319/27319 [==============================] - 1s 33us/step - loss: 0.1427 - val_loss: 0.1409\n",
      "Epoch 9/20\n",
      "27319/27319 [==============================] - 1s 31us/step - loss: 0.1379 - val_loss: 0.1349\n",
      "Epoch 10/20\n",
      "27319/27319 [==============================] - 1s 31us/step - loss: 0.1310 - val_loss: 0.1281\n",
      "Epoch 11/20\n",
      "27319/27319 [==============================] - 1s 31us/step - loss: 0.1255 - val_loss: 0.1240\n",
      "Epoch 12/20\n",
      "27319/27319 [==============================] - 1s 32us/step - loss: 0.1218 - val_loss: 0.1209\n",
      "Epoch 13/20\n",
      "27319/27319 [==============================] - 1s 31us/step - loss: 0.1191 - val_loss: 0.1185\n",
      "Epoch 14/20\n",
      "27319/27319 [==============================] - 1s 32us/step - loss: 0.1164 - val_loss: 0.1160\n",
      "Epoch 15/20\n",
      "27319/27319 [==============================] - 1s 31us/step - loss: 0.1140 - val_loss: 0.1142\n",
      "Epoch 16/20\n",
      "27319/27319 [==============================] - 1s 31us/step - loss: 0.1115 - val_loss: 0.1117\n",
      "Epoch 17/20\n",
      "27319/27319 [==============================] - 1s 31us/step - loss: 0.1094 - val_loss: 0.1097\n",
      "Epoch 18/20\n",
      "27319/27319 [==============================] - 1s 31us/step - loss: 0.1078 - val_loss: 0.1084\n",
      "Epoch 19/20\n",
      "27319/27319 [==============================] - 1s 32us/step - loss: 0.1061 - val_loss: 0.1068\n",
      "Epoch 20/20\n",
      "27319/27319 [==============================] - 1s 31us/step - loss: 0.1047 - val_loss: 0.1058\n",
      "Train on 27319 samples, validate on 3036 samples\n",
      "Epoch 1/20\n",
      "27319/27319 [==============================] - 2s 67us/step - loss: 0.2412 - acc: 0.9635 - val_loss: 0.1572 - val_acc: 0.9634\n",
      "Epoch 2/20\n",
      "27319/27319 [==============================] - 0s 15us/step - loss: 0.1594 - acc: 0.9635 - val_loss: 0.1573 - val_acc: 0.9634\n",
      "Epoch 3/20\n",
      "27319/27319 [==============================] - 0s 15us/step - loss: 0.1589 - acc: 0.9635 - val_loss: 0.1559 - val_acc: 0.9634\n",
      "Epoch 4/20\n",
      "27319/27319 [==============================] - 0s 15us/step - loss: 0.1586 - acc: 0.9635 - val_loss: 0.1566 - val_acc: 0.9634\n",
      "Epoch 5/20\n",
      "27319/27319 [==============================] - 0s 15us/step - loss: 0.1583 - acc: 0.9635 - val_loss: 0.1572 - val_acc: 0.9634\n",
      "Epoch 6/20\n",
      "27319/27319 [==============================] - 0s 15us/step - loss: 0.1579 - acc: 0.9635 - val_loss: 0.1551 - val_acc: 0.9634\n",
      "Epoch 7/20\n",
      "27319/27319 [==============================] - 0s 15us/step - loss: 0.1576 - acc: 0.9635 - val_loss: 0.1550 - val_acc: 0.9634\n",
      "Epoch 8/20\n",
      "27319/27319 [==============================] - 0s 15us/step - loss: 0.1574 - acc: 0.9635 - val_loss: 0.1551 - val_acc: 0.9634\n",
      "Epoch 9/20\n",
      "27319/27319 [==============================] - 0s 15us/step - loss: 0.1571 - acc: 0.9635 - val_loss: 0.1568 - val_acc: 0.9634\n",
      "Epoch 10/20\n",
      "27319/27319 [==============================] - 0s 15us/step - loss: 0.1571 - acc: 0.9635 - val_loss: 0.1550 - val_acc: 0.9634\n",
      "Epoch 11/20\n",
      "27319/27319 [==============================] - 0s 15us/step - loss: 0.1568 - acc: 0.9635 - val_loss: 0.1544 - val_acc: 0.9634\n",
      "Epoch 12/20\n",
      "27319/27319 [==============================] - 0s 15us/step - loss: 0.1570 - acc: 0.9635 - val_loss: 0.1544 - val_acc: 0.9634\n",
      "Epoch 13/20\n",
      "27319/27319 [==============================] - 0s 15us/step - loss: 0.1562 - acc: 0.9635 - val_loss: 0.1541 - val_acc: 0.9634\n",
      "Epoch 14/20\n",
      "27319/27319 [==============================] - 0s 15us/step - loss: 0.1558 - acc: 0.9635 - val_loss: 0.1538 - val_acc: 0.9634\n",
      "Epoch 15/20\n",
      "27319/27319 [==============================] - 0s 16us/step - loss: 0.1556 - acc: 0.9635 - val_loss: 0.1545 - val_acc: 0.9634\n",
      "Epoch 16/20\n",
      "27319/27319 [==============================] - 0s 16us/step - loss: 0.1556 - acc: 0.9635 - val_loss: 0.1542 - val_acc: 0.9634\n",
      "Epoch 17/20\n",
      "27319/27319 [==============================] - 0s 15us/step - loss: 0.1554 - acc: 0.9635 - val_loss: 0.1537 - val_acc: 0.9634\n",
      "Epoch 18/20\n",
      "27319/27319 [==============================] - 0s 15us/step - loss: 0.1551 - acc: 0.9635 - val_loss: 0.1538 - val_acc: 0.9634\n",
      "Epoch 19/20\n",
      "27319/27319 [==============================] - 0s 16us/step - loss: 0.1552 - acc: 0.9635 - val_loss: 0.1541 - val_acc: 0.9634\n",
      "Epoch 20/20\n",
      "27319/27319 [==============================] - 0s 15us/step - loss: 0.1554 - acc: 0.9635 - val_loss: 0.1542 - val_acc: 0.9634\n",
      "8929/8929 [==============================] - 0s 54us/step\n",
      "data sample 70.0\n",
      "Train on 31872 samples, validate on 3542 samples\n",
      "Epoch 1/20\n",
      "31872/31872 [==============================] - 3s 91us/step - loss: 0.2552 - val_loss: 0.1995\n",
      "Epoch 2/20\n",
      "31872/31872 [==============================] - 1s 33us/step - loss: 0.1916 - val_loss: 0.1838\n",
      "Epoch 3/20\n",
      "31872/31872 [==============================] - 1s 33us/step - loss: 0.1768 - val_loss: 0.1668\n",
      "Epoch 4/20\n",
      "31872/31872 [==============================] - 1s 33us/step - loss: 0.1608 - val_loss: 0.1559\n",
      "Epoch 5/20\n",
      "31872/31872 [==============================] - 1s 33us/step - loss: 0.1524 - val_loss: 0.1492\n",
      "Epoch 6/20\n",
      "31872/31872 [==============================] - 1s 33us/step - loss: 0.1458 - val_loss: 0.1419\n",
      "Epoch 7/20\n",
      "31872/31872 [==============================] - 1s 33us/step - loss: 0.1380 - val_loss: 0.1340\n",
      "Epoch 8/20\n",
      "31872/31872 [==============================] - 1s 34us/step - loss: 0.1325 - val_loss: 0.1296\n",
      "Epoch 9/20\n",
      "31872/31872 [==============================] - 1s 33us/step - loss: 0.1280 - val_loss: 0.1261\n",
      "Epoch 10/20\n",
      "31872/31872 [==============================] - 1s 34us/step - loss: 0.1229 - val_loss: 0.1200\n",
      "Epoch 11/20\n",
      "31872/31872 [==============================] - 1s 36us/step - loss: 0.1184 - val_loss: 0.1175\n",
      "Epoch 12/20\n",
      "31872/31872 [==============================] - 1s 36us/step - loss: 0.1154 - val_loss: 0.1144\n",
      "Epoch 13/20\n",
      "31872/31872 [==============================] - 1s 36us/step - loss: 0.1131 - val_loss: 0.1129\n",
      "Epoch 14/20\n",
      "31872/31872 [==============================] - 1s 36us/step - loss: 0.1112 - val_loss: 0.1112\n",
      "Epoch 15/20\n",
      "31872/31872 [==============================] - 1s 36us/step - loss: 0.1095 - val_loss: 0.1096\n",
      "Epoch 16/20\n",
      "31872/31872 [==============================] - 1s 36us/step - loss: 0.1079 - val_loss: 0.1073\n",
      "Epoch 17/20\n",
      "31872/31872 [==============================] - 1s 36us/step - loss: 0.1062 - val_loss: 0.1060\n",
      "Epoch 18/20\n",
      "31872/31872 [==============================] - 1s 36us/step - loss: 0.1046 - val_loss: 0.1045\n",
      "Epoch 19/20\n",
      "31872/31872 [==============================] - 1s 35us/step - loss: 0.1027 - val_loss: 0.1028\n",
      "Epoch 20/20\n",
      "31872/31872 [==============================] - 1s 33us/step - loss: 0.1013 - val_loss: 0.1015\n",
      "Train on 31872 samples, validate on 3542 samples\n",
      "Epoch 1/20\n",
      "31872/31872 [==============================] - 2s 69us/step - loss: 0.2337 - acc: 0.9571 - val_loss: 0.1572 - val_acc: 0.9636\n",
      "Epoch 2/20\n",
      "31872/31872 [==============================] - 1s 16us/step - loss: 0.1615 - acc: 0.9635 - val_loss: 0.1556 - val_acc: 0.9636\n",
      "Epoch 3/20\n",
      "31872/31872 [==============================] - 0s 16us/step - loss: 0.1605 - acc: 0.9635 - val_loss: 0.1540 - val_acc: 0.9636\n",
      "Epoch 4/20\n",
      "31872/31872 [==============================] - 1s 16us/step - loss: 0.1600 - acc: 0.9635 - val_loss: 0.1540 - val_acc: 0.9636\n",
      "Epoch 5/20\n",
      "31872/31872 [==============================] - 1s 16us/step - loss: 0.1603 - acc: 0.9635 - val_loss: 0.1526 - val_acc: 0.9636\n",
      "Epoch 6/20\n",
      "31872/31872 [==============================] - 1s 16us/step - loss: 0.1588 - acc: 0.9635 - val_loss: 0.1521 - val_acc: 0.9636\n",
      "Epoch 7/20\n",
      "31872/31872 [==============================] - 1s 16us/step - loss: 0.1585 - acc: 0.9635 - val_loss: 0.1522 - val_acc: 0.9636\n",
      "Epoch 8/20\n",
      "31872/31872 [==============================] - 1s 16us/step - loss: 0.1580 - acc: 0.9635 - val_loss: 0.1517 - val_acc: 0.9636\n",
      "Epoch 9/20\n",
      "31872/31872 [==============================] - 1s 16us/step - loss: 0.1576 - acc: 0.9635 - val_loss: 0.1513 - val_acc: 0.9636\n",
      "Epoch 10/20\n",
      "31872/31872 [==============================] - 1s 16us/step - loss: 0.1565 - acc: 0.9635 - val_loss: 0.1517 - val_acc: 0.9636\n",
      "Epoch 11/20\n",
      "31872/31872 [==============================] - 1s 16us/step - loss: 0.1563 - acc: 0.9635 - val_loss: 0.1519 - val_acc: 0.9636\n",
      "Epoch 12/20\n",
      "31872/31872 [==============================] - 1s 16us/step - loss: 0.1563 - acc: 0.9635 - val_loss: 0.1511 - val_acc: 0.9636\n",
      "Epoch 13/20\n",
      "31872/31872 [==============================] - 1s 16us/step - loss: 0.1564 - acc: 0.9635 - val_loss: 0.1530 - val_acc: 0.9636\n",
      "Epoch 14/20\n",
      "31872/31872 [==============================] - 1s 16us/step - loss: 0.1560 - acc: 0.9635 - val_loss: 0.1518 - val_acc: 0.9636\n",
      "Epoch 15/20\n",
      "31872/31872 [==============================] - 1s 16us/step - loss: 0.1554 - acc: 0.9635 - val_loss: 0.1505 - val_acc: 0.9636\n",
      "Epoch 16/20\n",
      "31872/31872 [==============================] - 1s 16us/step - loss: 0.1553 - acc: 0.9635 - val_loss: 0.1509 - val_acc: 0.9636\n",
      "Epoch 17/20\n",
      "31872/31872 [==============================] - 1s 16us/step - loss: 0.1551 - acc: 0.9635 - val_loss: 0.1512 - val_acc: 0.9636\n",
      "Epoch 18/20\n",
      "31872/31872 [==============================] - 1s 16us/step - loss: 0.1556 - acc: 0.9635 - val_loss: 0.1540 - val_acc: 0.9636\n",
      "Epoch 19/20\n",
      "31872/31872 [==============================] - 1s 16us/step - loss: 0.1546 - acc: 0.9635 - val_loss: 0.1520 - val_acc: 0.9636\n",
      "Epoch 20/20\n",
      "31872/31872 [==============================] - 1s 16us/step - loss: 0.1546 - acc: 0.9635 - val_loss: 0.1514 - val_acc: 0.9636\n",
      "8929/8929 [==============================] - 1s 67us/step\n",
      "data sample 80.0\n",
      "Train on 36425 samples, validate on 4048 samples\n",
      "Epoch 1/20\n",
      "36425/36425 [==============================] - 3s 92us/step - loss: 0.2447 - val_loss: 0.1995\n",
      "Epoch 2/20\n",
      "36425/36425 [==============================] - 1s 34us/step - loss: 0.1960 - val_loss: 0.1896\n",
      "Epoch 3/20\n",
      "36425/36425 [==============================] - 1s 34us/step - loss: 0.1820 - val_loss: 0.1701\n",
      "Epoch 4/20\n",
      "36425/36425 [==============================] - 1s 34us/step - loss: 0.1631 - val_loss: 0.1550\n",
      "Epoch 5/20\n",
      "36425/36425 [==============================] - 1s 34us/step - loss: 0.1527 - val_loss: 0.1490\n",
      "Epoch 6/20\n",
      "36425/36425 [==============================] - 1s 34us/step - loss: 0.1470 - val_loss: 0.1435\n",
      "Epoch 7/20\n",
      "36425/36425 [==============================] - 1s 34us/step - loss: 0.1426 - val_loss: 0.1393\n",
      "Epoch 8/20\n",
      "36425/36425 [==============================] - 1s 34us/step - loss: 0.1380 - val_loss: 0.1342\n",
      "Epoch 9/20\n",
      "36425/36425 [==============================] - 1s 34us/step - loss: 0.1328 - val_loss: 0.1294\n",
      "Epoch 10/20\n",
      "36425/36425 [==============================] - 1s 37us/step - loss: 0.1278 - val_loss: 0.1253\n",
      "Epoch 11/20\n",
      "36425/36425 [==============================] - 1s 38us/step - loss: 0.1241 - val_loss: 0.1221\n",
      "Epoch 12/20\n",
      "36425/36425 [==============================] - 1s 38us/step - loss: 0.1217 - val_loss: 0.1203\n",
      "Epoch 13/20\n",
      "36425/36425 [==============================] - 1s 38us/step - loss: 0.1199 - val_loss: 0.1193\n",
      "Epoch 14/20\n",
      "36425/36425 [==============================] - 1s 38us/step - loss: 0.1183 - val_loss: 0.1173\n",
      "Epoch 15/20\n",
      "36425/36425 [==============================] - 1s 38us/step - loss: 0.1169 - val_loss: 0.1164\n",
      "Epoch 16/20\n",
      "36425/36425 [==============================] - 1s 38us/step - loss: 0.1159 - val_loss: 0.1153\n",
      "Epoch 17/20\n",
      "36425/36425 [==============================] - 1s 37us/step - loss: 0.1148 - val_loss: 0.1142\n",
      "Epoch 18/20\n",
      "36425/36425 [==============================] - 1s 33us/step - loss: 0.1137 - val_loss: 0.1139\n",
      "Epoch 19/20\n",
      "36425/36425 [==============================] - 1s 34us/step - loss: 0.1130 - val_loss: 0.1135\n",
      "Epoch 20/20\n",
      "36425/36425 [==============================] - 1s 34us/step - loss: 0.1121 - val_loss: 0.1125\n",
      "Train on 36425 samples, validate on 4048 samples\n",
      "Epoch 1/20\n",
      "36425/36425 [==============================] - 3s 70us/step - loss: 0.2781 - acc: 0.9569 - val_loss: 0.1671 - val_acc: 0.9634\n",
      "Epoch 2/20\n",
      "36425/36425 [==============================] - 1s 16us/step - loss: 0.1644 - acc: 0.9635 - val_loss: 0.1638 - val_acc: 0.9634\n",
      "Epoch 3/20\n",
      "36425/36425 [==============================] - 1s 16us/step - loss: 0.1623 - acc: 0.9635 - val_loss: 0.1619 - val_acc: 0.9634\n",
      "Epoch 4/20\n",
      "36425/36425 [==============================] - 1s 16us/step - loss: 0.1610 - acc: 0.9635 - val_loss: 0.1605 - val_acc: 0.9634\n",
      "Epoch 5/20\n",
      "36425/36425 [==============================] - 1s 16us/step - loss: 0.1597 - acc: 0.9635 - val_loss: 0.1595 - val_acc: 0.9634\n",
      "Epoch 6/20\n",
      "36425/36425 [==============================] - 1s 16us/step - loss: 0.1593 - acc: 0.9635 - val_loss: 0.1595 - val_acc: 0.9634\n",
      "Epoch 7/20\n",
      "36425/36425 [==============================] - 1s 16us/step - loss: 0.1581 - acc: 0.9635 - val_loss: 0.1615 - val_acc: 0.9634\n",
      "Epoch 8/20\n",
      "36425/36425 [==============================] - 1s 16us/step - loss: 0.1578 - acc: 0.9635 - val_loss: 0.1591 - val_acc: 0.9634\n",
      "Epoch 9/20\n",
      "36425/36425 [==============================] - 1s 16us/step - loss: 0.1570 - acc: 0.9635 - val_loss: 0.1582 - val_acc: 0.9634\n",
      "Epoch 10/20\n",
      "36425/36425 [==============================] - 1s 16us/step - loss: 0.1572 - acc: 0.9635 - val_loss: 0.1586 - val_acc: 0.9634\n",
      "Epoch 11/20\n",
      "36425/36425 [==============================] - 1s 16us/step - loss: 0.1567 - acc: 0.9635 - val_loss: 0.1607 - val_acc: 0.9634\n",
      "Epoch 12/20\n",
      "36425/36425 [==============================] - 1s 16us/step - loss: 0.1564 - acc: 0.9635 - val_loss: 0.1584 - val_acc: 0.9634\n",
      "Epoch 13/20\n",
      "36425/36425 [==============================] - 1s 16us/step - loss: 0.1558 - acc: 0.9635 - val_loss: 0.1591 - val_acc: 0.9634\n",
      "Epoch 14/20\n",
      "36425/36425 [==============================] - 1s 16us/step - loss: 0.1560 - acc: 0.9635 - val_loss: 0.1580 - val_acc: 0.9634\n",
      "Epoch 15/20\n",
      "36425/36425 [==============================] - 1s 16us/step - loss: 0.1559 - acc: 0.9635 - val_loss: 0.1577 - val_acc: 0.9634\n",
      "Epoch 16/20\n",
      "36425/36425 [==============================] - 1s 16us/step - loss: 0.1559 - acc: 0.9635 - val_loss: 0.1594 - val_acc: 0.9634\n",
      "Epoch 17/20\n",
      "36425/36425 [==============================] - 1s 16us/step - loss: 0.1561 - acc: 0.9635 - val_loss: 0.1572 - val_acc: 0.9634\n",
      "Epoch 18/20\n",
      "36425/36425 [==============================] - 1s 16us/step - loss: 0.1554 - acc: 0.9635 - val_loss: 0.1568 - val_acc: 0.9634\n",
      "Epoch 19/20\n",
      "36425/36425 [==============================] - 1s 16us/step - loss: 0.1551 - acc: 0.9635 - val_loss: 0.1578 - val_acc: 0.9634\n",
      "Epoch 20/20\n",
      "36425/36425 [==============================] - 1s 16us/step - loss: 0.1554 - acc: 0.9635 - val_loss: 0.1570 - val_acc: 0.9634\n",
      "8929/8929 [==============================] - 1s 78us/step\n",
      "data sample 90.0\n",
      "Train on 40978 samples, validate on 4554 samples\n",
      "Epoch 1/20\n",
      "40978/40978 [==============================] - 4s 95us/step - loss: 0.2447 - val_loss: 0.1997\n",
      "Epoch 2/20\n",
      "40978/40978 [==============================] - 2s 39us/step - loss: 0.1942 - val_loss: 0.1845\n",
      "Epoch 3/20\n",
      "40978/40978 [==============================] - 2s 39us/step - loss: 0.1790 - val_loss: 0.1742\n",
      "Epoch 4/20\n",
      "40978/40978 [==============================] - 2s 39us/step - loss: 0.1662 - val_loss: 0.1591\n",
      "Epoch 5/20\n",
      "40978/40978 [==============================] - 2s 39us/step - loss: 0.1518 - val_loss: 0.1452\n",
      "Epoch 6/20\n",
      "40978/40978 [==============================] - 2s 39us/step - loss: 0.1402 - val_loss: 0.1376\n",
      "Epoch 7/20\n",
      "40978/40978 [==============================] - 2s 39us/step - loss: 0.1349 - val_loss: 0.1346\n",
      "Epoch 8/20\n",
      "40978/40978 [==============================] - 1s 36us/step - loss: 0.1309 - val_loss: 0.1301\n",
      "Epoch 9/20\n",
      "40978/40978 [==============================] - 1s 36us/step - loss: 0.1270 - val_loss: 0.1280\n",
      "Epoch 10/20\n",
      "40978/40978 [==============================] - 1s 36us/step - loss: 0.1239 - val_loss: 0.1247\n",
      "Epoch 11/20\n",
      "40978/40978 [==============================] - 1s 36us/step - loss: 0.1205 - val_loss: 0.1206\n",
      "Epoch 12/20\n",
      "40978/40978 [==============================] - 1s 36us/step - loss: 0.1158 - val_loss: 0.1156\n",
      "Epoch 13/20\n",
      "40978/40978 [==============================] - 1s 36us/step - loss: 0.1121 - val_loss: 0.1138\n",
      "Epoch 14/20\n",
      "40978/40978 [==============================] - 1s 36us/step - loss: 0.1096 - val_loss: 0.1116\n",
      "Epoch 15/20\n",
      "40978/40978 [==============================] - 1s 36us/step - loss: 0.1076 - val_loss: 0.1095\n",
      "Epoch 16/20\n",
      "40978/40978 [==============================] - 1s 36us/step - loss: 0.1062 - val_loss: 0.1081\n",
      "Epoch 17/20\n",
      "40978/40978 [==============================] - 1s 36us/step - loss: 0.1049 - val_loss: 0.1067\n",
      "Epoch 18/20\n",
      "40978/40978 [==============================] - 1s 36us/step - loss: 0.1038 - val_loss: 0.1058\n",
      "Epoch 19/20\n",
      "40978/40978 [==============================] - 1s 36us/step - loss: 0.1028 - val_loss: 0.1049\n",
      "Epoch 20/20\n",
      "40978/40978 [==============================] - 1s 36us/step - loss: 0.1020 - val_loss: 0.1037\n",
      "Train on 40978 samples, validate on 4554 samples\n",
      "Epoch 1/20\n",
      "40978/40978 [==============================] - 3s 71us/step - loss: 0.2211 - acc: 0.9609 - val_loss: 0.1630 - val_acc: 0.9635\n",
      "Epoch 2/20\n",
      "40978/40978 [==============================] - 1s 17us/step - loss: 0.1603 - acc: 0.9635 - val_loss: 0.1624 - val_acc: 0.9635\n",
      "Epoch 3/20\n",
      "40978/40978 [==============================] - 1s 17us/step - loss: 0.1603 - acc: 0.9635 - val_loss: 0.1627 - val_acc: 0.9635\n",
      "Epoch 4/20\n",
      "40978/40978 [==============================] - 1s 17us/step - loss: 0.1597 - acc: 0.9635 - val_loss: 0.1622 - val_acc: 0.9635\n",
      "Epoch 5/20\n",
      "40978/40978 [==============================] - 1s 17us/step - loss: 0.1587 - acc: 0.9635 - val_loss: 0.1605 - val_acc: 0.9635\n",
      "Epoch 6/20\n",
      "40978/40978 [==============================] - 1s 17us/step - loss: 0.1581 - acc: 0.9635 - val_loss: 0.1613 - val_acc: 0.9635\n",
      "Epoch 7/20\n",
      "40978/40978 [==============================] - 1s 17us/step - loss: 0.1577 - acc: 0.9635 - val_loss: 0.1598 - val_acc: 0.9635\n",
      "Epoch 8/20\n",
      "40978/40978 [==============================] - 1s 17us/step - loss: 0.1575 - acc: 0.9635 - val_loss: 0.1587 - val_acc: 0.9635\n",
      "Epoch 9/20\n",
      "40978/40978 [==============================] - 1s 16us/step - loss: 0.1565 - acc: 0.9635 - val_loss: 0.1587 - val_acc: 0.9635\n",
      "Epoch 10/20\n",
      "40978/40978 [==============================] - 1s 17us/step - loss: 0.1564 - acc: 0.9635 - val_loss: 0.1578 - val_acc: 0.9635\n",
      "Epoch 11/20\n",
      "40978/40978 [==============================] - 1s 17us/step - loss: 0.1557 - acc: 0.9635 - val_loss: 0.1583 - val_acc: 0.9635\n",
      "Epoch 12/20\n",
      "40978/40978 [==============================] - 1s 17us/step - loss: 0.1554 - acc: 0.9635 - val_loss: 0.1581 - val_acc: 0.9635\n",
      "Epoch 13/20\n",
      "40978/40978 [==============================] - 1s 17us/step - loss: 0.1554 - acc: 0.9635 - val_loss: 0.1578 - val_acc: 0.9635\n",
      "Epoch 14/20\n",
      "40978/40978 [==============================] - 1s 17us/step - loss: 0.1553 - acc: 0.9635 - val_loss: 0.1570 - val_acc: 0.9635\n",
      "Epoch 15/20\n",
      "40978/40978 [==============================] - 1s 17us/step - loss: 0.1557 - acc: 0.9635 - val_loss: 0.1564 - val_acc: 0.9635\n",
      "Epoch 16/20\n",
      "40978/40978 [==============================] - 1s 16us/step - loss: 0.1555 - acc: 0.9635 - val_loss: 0.1579 - val_acc: 0.9635\n",
      "Epoch 17/20\n",
      "40978/40978 [==============================] - 1s 17us/step - loss: 0.1548 - acc: 0.9635 - val_loss: 0.1573 - val_acc: 0.9635\n",
      "Epoch 18/20\n",
      "40978/40978 [==============================] - 1s 16us/step - loss: 0.1549 - acc: 0.9635 - val_loss: 0.1563 - val_acc: 0.9635\n",
      "Epoch 19/20\n",
      "40978/40978 [==============================] - 1s 16us/step - loss: 0.1553 - acc: 0.9635 - val_loss: 0.1560 - val_acc: 0.9635\n",
      "Epoch 20/20\n",
      "40978/40978 [==============================] - 1s 16us/step - loss: 0.1549 - acc: 0.9635 - val_loss: 0.1572 - val_acc: 0.9635\n",
      "8929/8929 [==============================] - 1s 89us/step\n",
      "data sample 99.0\n",
      "Train on 45077 samples, validate on 5009 samples\n",
      "Epoch 1/20\n",
      "45077/45077 [==============================] - 4s 96us/step - loss: 0.2373 - val_loss: 0.1961\n",
      "Epoch 2/20\n",
      "45077/45077 [==============================] - 2s 38us/step - loss: 0.1868 - val_loss: 0.1761\n",
      "Epoch 3/20\n",
      "45077/45077 [==============================] - 2s 38us/step - loss: 0.1673 - val_loss: 0.1593\n",
      "Epoch 4/20\n",
      "45077/45077 [==============================] - 2s 38us/step - loss: 0.1497 - val_loss: 0.1433\n",
      "Epoch 5/20\n",
      "45077/45077 [==============================] - 2s 38us/step - loss: 0.1384 - val_loss: 0.1356\n",
      "Epoch 6/20\n",
      "45077/45077 [==============================] - 2s 38us/step - loss: 0.1310 - val_loss: 0.1270\n",
      "Epoch 7/20\n",
      "45077/45077 [==============================] - 2s 38us/step - loss: 0.1230 - val_loss: 0.1226\n",
      "Epoch 8/20\n",
      "45077/45077 [==============================] - 2s 37us/step - loss: 0.1179 - val_loss: 0.1188\n",
      "Epoch 9/20\n",
      "45077/45077 [==============================] - 2s 38us/step - loss: 0.1144 - val_loss: 0.1149\n",
      "Epoch 10/20\n",
      "45077/45077 [==============================] - 2s 38us/step - loss: 0.1112 - val_loss: 0.1119\n",
      "Epoch 11/20\n",
      "45077/45077 [==============================] - 2s 38us/step - loss: 0.1084 - val_loss: 0.1090\n",
      "Epoch 12/20\n",
      "45077/45077 [==============================] - 2s 38us/step - loss: 0.1061 - val_loss: 0.1070\n",
      "Epoch 13/20\n",
      "45077/45077 [==============================] - 2s 38us/step - loss: 0.1042 - val_loss: 0.1056\n",
      "Epoch 14/20\n",
      "45077/45077 [==============================] - 2s 38us/step - loss: 0.1028 - val_loss: 0.1040\n",
      "Epoch 15/20\n",
      "45077/45077 [==============================] - 2s 38us/step - loss: 0.1017 - val_loss: 0.1030\n",
      "Epoch 16/20\n",
      "45077/45077 [==============================] - 2s 41us/step - loss: 0.1006 - val_loss: 0.1031\n",
      "Epoch 17/20\n",
      "45077/45077 [==============================] - 2s 41us/step - loss: 0.0996 - val_loss: 0.1031\n",
      "Epoch 18/20\n",
      "45077/45077 [==============================] - 2s 41us/step - loss: 0.0990 - val_loss: 0.1007\n",
      "Epoch 19/20\n",
      "45077/45077 [==============================] - 2s 41us/step - loss: 0.0982 - val_loss: 0.0995\n",
      "Epoch 20/20\n",
      "45077/45077 [==============================] - 2s 41us/step - loss: 0.0977 - val_loss: 0.0999\n",
      "Train on 45077 samples, validate on 5009 samples\n",
      "Epoch 1/20\n",
      "45077/45077 [==============================] - 3s 76us/step - loss: 0.2132 - acc: 0.9632 - val_loss: 0.1656 - val_acc: 0.9635\n",
      "Epoch 2/20\n",
      "45077/45077 [==============================] - 1s 17us/step - loss: 0.1598 - acc: 0.9635 - val_loss: 0.1656 - val_acc: 0.9635\n",
      "Epoch 3/20\n",
      "45077/45077 [==============================] - 1s 17us/step - loss: 0.1596 - acc: 0.9635 - val_loss: 0.1643 - val_acc: 0.9635\n",
      "Epoch 4/20\n",
      "45077/45077 [==============================] - 1s 17us/step - loss: 0.1590 - acc: 0.9635 - val_loss: 0.1637 - val_acc: 0.9635\n",
      "Epoch 5/20\n",
      "45077/45077 [==============================] - 1s 16us/step - loss: 0.1587 - acc: 0.9635 - val_loss: 0.1633 - val_acc: 0.9635\n",
      "Epoch 6/20\n",
      "45077/45077 [==============================] - 1s 16us/step - loss: 0.1579 - acc: 0.9635 - val_loss: 0.1631 - val_acc: 0.9635\n",
      "Epoch 7/20\n",
      "45077/45077 [==============================] - 1s 17us/step - loss: 0.1577 - acc: 0.9635 - val_loss: 0.1617 - val_acc: 0.9635\n",
      "Epoch 8/20\n",
      "45077/45077 [==============================] - 1s 17us/step - loss: 0.1571 - acc: 0.9635 - val_loss: 0.1612 - val_acc: 0.9635\n",
      "Epoch 9/20\n",
      "45077/45077 [==============================] - 1s 17us/step - loss: 0.1568 - acc: 0.9635 - val_loss: 0.1608 - val_acc: 0.9635\n",
      "Epoch 10/20\n",
      "45077/45077 [==============================] - 1s 17us/step - loss: 0.1567 - acc: 0.9635 - val_loss: 0.1597 - val_acc: 0.9635\n",
      "Epoch 11/20\n",
      "45077/45077 [==============================] - 1s 17us/step - loss: 0.1560 - acc: 0.9635 - val_loss: 0.1603 - val_acc: 0.9635\n",
      "Epoch 12/20\n",
      "45077/45077 [==============================] - 1s 17us/step - loss: 0.1555 - acc: 0.9635 - val_loss: 0.1622 - val_acc: 0.9635\n",
      "Epoch 13/20\n",
      "45077/45077 [==============================] - 1s 19us/step - loss: 0.1551 - acc: 0.9635 - val_loss: 0.1610 - val_acc: 0.9635\n",
      "Epoch 14/20\n",
      "45077/45077 [==============================] - 1s 19us/step - loss: 0.1552 - acc: 0.9635 - val_loss: 0.1575 - val_acc: 0.9635\n",
      "Epoch 15/20\n",
      "45077/45077 [==============================] - 1s 19us/step - loss: 0.1550 - acc: 0.9635 - val_loss: 0.1570 - val_acc: 0.9635\n",
      "Epoch 16/20\n",
      "45077/45077 [==============================] - 1s 19us/step - loss: 0.1547 - acc: 0.9635 - val_loss: 0.1568 - val_acc: 0.9635\n",
      "Epoch 17/20\n",
      "45077/45077 [==============================] - 1s 19us/step - loss: 0.1542 - acc: 0.9635 - val_loss: 0.1565 - val_acc: 0.9635\n",
      "Epoch 18/20\n",
      "45077/45077 [==============================] - 1s 19us/step - loss: 0.1546 - acc: 0.9635 - val_loss: 0.1620 - val_acc: 0.9635\n",
      "Epoch 19/20\n",
      "45077/45077 [==============================] - 1s 16us/step - loss: 0.1548 - acc: 0.9635 - val_loss: 0.1563 - val_acc: 0.9635\n",
      "Epoch 20/20\n",
      "45077/45077 [==============================] - 1s 17us/step - loss: 0.1543 - acc: 0.9635 - val_loss: 0.1599 - val_acc: 0.9635\n",
      "8929/8929 [==============================] - 1s 99us/step\n"
     ]
    }
   ],
   "source": [
    "#main code to run all functions to reach objective\n",
    "ROC_list_NN,ROC_list_SOAM = data_sampling(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5950299226390308,\n",
       " 0.5912861307913124,\n",
       " 0.5920299862644045,\n",
       " 0.6020629591787087,\n",
       " 0.596966005337046,\n",
       " 0.6150408512326481,\n",
       " 0.604314361743934,\n",
       " 0.5998405622985976,\n",
       " 0.6127557646459997,\n",
       " 0.6211627349928328]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evalution output for Neural network\n",
    "ROC_list_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5710459637185663,\n",
       " 0.5888030570120776,\n",
       " 0.6316760794793198,\n",
       " 0.6321293167009121,\n",
       " 0.6171081144807609,\n",
       " 0.6274536002604897,\n",
       " 0.6268925741703439,\n",
       " 0.6331963516462129,\n",
       " 0.639275568979262,\n",
       " 0.6400469330698495]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evalution output for State of art model\n",
    "ROC_list_SOAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving output to a file\n",
    "with open('ROC_scores_NN.txt', 'w') as f:\n",
    "    print(ROC_list_NN, file=f)\n",
    "with open('ROC_scores_SOAM.txt', 'w') as f:\n",
    "    print(ROC_list_SOAM, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'ROC are under curve Value')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##output comparitive visualization\n",
    "from matplotlib.pyplot import figure\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(ROC_list_NN,label='NN')\n",
    "plt.plot(ROC_list_SOAM,label='SOAM1')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel(\"data fraction\")\n",
    "plt.ylabel(\"ROC are under curve Value\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
