{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We have loaded the necessary libraries above\n",
    "* Now let's load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataset_Facebook.csv\", delimiter = \";\")\n",
    "\n",
    "features = [\"Category\",\n",
    "            \"Page total likes\",\n",
    "            \"Type\",\n",
    "            \"Post Month\",\n",
    "            \"Post Hour\",\n",
    "            \"Post Weekday\",\n",
    "            \"Paid\"]\n",
    "\n",
    "\n",
    "df[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes=  [\"Lifetime Post Total Reach\",\n",
    "            \"Lifetime Post Total Impressions\",\n",
    "            \"Lifetime Engaged Users\",\n",
    "            \"Lifetime Post Consumers\",\n",
    "            \"Lifetime Post Consumptions\",\n",
    "            \"Lifetime Post Impressions by people who have liked your Page\",\n",
    "            \"Lifetime Post reach by people who like your Page\",\n",
    "            \"Lifetime People who have liked your Page and engaged with your post\",\n",
    "            \"comment\",\n",
    "            \"like\",\n",
    "            \"share\",\n",
    "            \"Total Interactions\"]\n",
    "\n",
    "df[outcomes].head()\n",
    "\n",
    "print(df[outcomes[-3:]].head().to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# convert a string variable to a categorical one\n",
    "#types = list(set(df[\"Type\"]))\n",
    "#to_categorical = {types[i]:i for i in range(len(types))}\n",
    "#df[\"Type\"] = df[\"Type\"].apply(lambda x: to_categorical[x])\n",
    "\n",
    "df[[\"Type\"]] = df[[\"Type\"]].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's prepare the data by cleaning it up and choosing the relevant column we would like to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the bootstrap to find an approximation of the bias and the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "outcomes_of_interest = [\"Lifetime Post Consumers\", \"like\"]\n",
    "n_bins = 10\n",
    "\n",
    "X_df = df[features].copy()\n",
    "y_df = df[outcomes_of_interest].copy()\n",
    "\n",
    "#print X_df.head().to_latex()\n",
    "\n",
    "#print y_df.values\n",
    "bins =  pd.qcut(y_df[outcomes_of_interest[0]].values,n_bins)\n",
    "\n",
    "y_df = df[outcomes_of_interest].copy()\n",
    "y_df[outcomes_of_interest[0]] = bins\n",
    "\n",
    "y_df[outcomes_of_interest] = y_df[outcomes_of_interest].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "\n",
    "print(y_df.head())\n",
    "\n",
    "X = X_df.values\n",
    "y = y_df.values.T[0]\n",
    "\n",
    "# # import seaborn as sns\n",
    "\n",
    "y_df['id'] = range(1, len(df) + 1)\n",
    "\n",
    "y_df.head()\n",
    "# sns_plot = sns.lmplot(x=\"id\", y= attribute, data=y_df, fit_reg=False, aspect = 2)\n",
    "\n",
    "# sns_plot.savefig(\"scaterplot_lpc.png\",bbox_inches='tight')\n",
    "# sns_plot.savefig(\"scaterplot_lpc.pdf\",bbox_inches='tight')\n",
    "\n",
    "\n",
    "sns_plot = sns.jointplot(x=\"Lifetime Post Consumers\", y=\"like\", data=y_df, ratio = 2)\n",
    "\n",
    "sns_plot.savefig(\"joint_plot.png\",bbox_inches='tight')\n",
    "sns_plot.savefig(\"joint_plot.pdf\",bbox_inches='tight')\n",
    "\n",
    "# sns.distplot(y, kde=False, rug=True)\n",
    "\n",
    "sns_plot.savefig(\"histogram_lpc.png\",bbox_inches='tight')\n",
    "sns_plot.savefig(\"histogram_lpc.pdf\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators = 2000,max_depth = 4)\n",
    "\n",
    "dummy_clf = DummyClassifier()\n",
    "scores = cross_val_score(clf, X, y, cv=10,scoring = make_scorer(acc))\n",
    "\n",
    "dummy_clf.fit(X,y)\n",
    "\n",
    "print(\"ACC: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "print(\"Dummy ACC: %0.2f\"% (acc(y,dummy_clf.predict(X))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the regressor on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators = 20000,max_depth = 4)\n",
    "clf.fit(X,y)\n",
    "\n",
    "print(acc(y,clf.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(indices)\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, features[indices[f]],  importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "fig = plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), np.array(features)[indices])\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "fig.set_size_inches(15,8)\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0,None])\n",
    "\n",
    "plt.savefig(\"importances.png\",bbox_inches='tight')\n",
    "plt.savefig(\"importances.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        t = \"(%.2f)\"%(cm[i, j])\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_pred = clf.predict(X)\n",
    "cnf_matrix = confusion_matrix(y, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=range(len(set(y))), normalize = True,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "plt.savefig(\"confusion.png\",bbox_inches='tight')\n",
    "plt.savefig(\"confusion.pdf\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
